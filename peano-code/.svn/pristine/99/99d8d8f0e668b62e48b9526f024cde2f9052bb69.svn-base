\section{Matrix-free multigrid}
  \label{section:applications:matrix-free-multigrid}

\chapterDescription
  {
    1--2 days.
  }
  {
    Chapter \ref{chapter:quickstart}. It is advantageous if the reader has
    studied the implementation of the heat equation before.
  }

In this section, we sketch how to solve the convection-diffusion equation
\[
  - \nabla (\epsilon \nabla) u + \nabla (v\ u) = f \qquad \mbox{with } v \in
  \mathbb{R}^d, \epsilon \in \mathbb{R}^{d \times d}
\]
with various geometric multigrid solvers. $epsilon$ is a diagonal matrix with
entries $\epsilon _1, \epsilon _2$ or $\epsilon _1, \epsilon _2, \epsilon _3$,
respectively.
Our realisation is based upon a few design decisions:

\begin{enumerate}
  \item The solvers use the spacetree as computational grid.
  \item We use a finite element formalism with $d$-linear shape functions.
  \item The material parameters $\epsilon $ and $v$ are given per cell.
\end{enumerate}


\noindent
For the implementation, we use Peano's \texttt{matrixfree} toolbox. 
This is a tiny little collection of helper classes to work with stencils and
local assembly matrix. 
It is neither fast, i.e.~computationally mature, nor can it cope with real
stencil libraries, but it does the job.



\subsection{Setup}

We start with Peano's PDT and generate a project. We also link Peano's sources
into the project and unzip the \texttt{matrixfree} toolbox. 
\begin{code}
  java -jar pdt.jar --create-project multigrid multigrid
  ln -s mypath/src/peano 
  ln -s mypath/src/tarch
  cp mypath/tarballs/toolboxes/matrixfree.tar.gz .
  tar -xzvf matrixfree.tar.gz
\end{code}


\noindent
I recommend to hold \texttt{matrixfree} parallel to the \texttt{multigrid},
\texttt{peano} and \texttt{tarch} directory.
As soon as we use such a toolbox, we also might have to adopt our makefile
accordingly: we have to add the matrixfree directory to the find pathes when we
build up a list of source codes.
Furthermore, you might have to add an additional search directory. If you place
your toolbox parallel to \texttt{peano} and \texttt{tarch}, this however should
not be necessary.
Here's the corresponding excerp from the makefile:
\begin{code}
files.mk:
    touch files.mk
    echo -n SOURCES= > files.mk
    find -H $(PEANO_HOME)/peano -name '*.cpp' | awk '{ printf "%s ", $$0 }' >> files.mk
    find -H $(PEANO_HOME)/tarch -name '*.cpp' | awk '{ printf "%s ", $$0 }' >> files.mk
    find -H $(PEANO_HOME)/matrixfree -name '*.cpp' | awk '{ printf "%s ", $$0 }' >> files.mk
    find $(PROJECT_HOME) -name '*.cpp' | awk '{ printf "%s ", $$0 }' >> files.mk
\end{code}

\noindent
We next add our material parameters to the \texttt{Cell.def} file
\begin{code}
Packed-Type: short int;

Constant: DIMENSIONS;

class multigrid::records::Cell {  
  persistent parallelise double   epsilon[DIMENSIONS];
  persistent parallelise double   v[DIMENSIONS];
};
\end{code}

\noindent
and create a simple first specification file:
\begin{code}
component: Multigrid

namespace: ::multigrid

vertex:
  dastgen-file: Vertex.def
  
cell:
  dastgen-file: Cell.def

state:
  dastgen-file: State.def

event-mapping:
  name: CreateGrid

event-mapping:
  name: PlotCells

adapter:
  name: CreateGrid
  merge-with-user-defined-mapping: CreateGrid
  merge-with-user-defined-mapping: PlotCells
  
\end{code}

\noindent
We run this specification file through the PDT

\begin{code}
java -jar <mypath>/pdt.jar --generate-gluecode multigrid/project.peano-specification multigrid
\end{code}


\noindent
and implement both the plotter and the creational mapping such that we have a
few characteristic setups. 
It might however make sense to validate that make passes before we start any
PDE-specific coding:
\begin{code}
make -f multigrid/makefile
\end{code}


\noindent
We next introduce an operation 
\begin{code}
matrixfree::stencil::ElementWiseAssemblyMatrix multigrid::Cell::getElementsAssemblyMatrix(
  const tarch::la::Vector<DIMENSIONS,double>&  h
) const {
  matrixfree::stencil::ElementWiseAssemblyMatrix result;

  const matrixfree::stencil::Stencil laplacianStencil = 
    matrixfree::stencil::getLaplacian(_cellData.getEpsilon(), h);

  return matrixfree::stencil::getElementWiseAssemblyMatrix(laplacianStencil);
}
\end{code}
which returns the $\mathbf{R}^{2^d \times 2^d}$ local system matrix. 
The method sets up the stencils that correspond to a regular Cartesian system
given the mesh size \textt{h} and the material parameters.
Here, also the convective term has to be handled.
Finally, it uses \texttt{getElementWiseAssemblyMatrix} to extract the actual
matrix from this stencil.

\begin{remark}
  Peano supports all stencil/linear algebra operations for complex values.
\end{remark}


\subsection{Jacobi smoother}

The basic building block of all of our solvers is a simple Jacobi smoother
working on adaptive grids as well as on multiple scales.
Its realisation is an extension of the solver in \ref{section:applications:heat-equation}.
To make it work without the assembly of any global matrix, we associate each
vertex a residual value as well as the actual value. 
There are a few other features such as boundary properties or some level
analysis that we either use later on or we pass to the used toolboxes. 
Their exact semantics and rationale have to be taken from the source code.

\begin{code}
Packed-Type: short int;


class multigrid::records::Vertex {  
  /**
   * Solution
   */
  persistent parallelise double  u;

  /**
   * Rhs
   */
  persistent parallelise double  f;
  
  /**
   * Residual
   */
  persistent parallelise double   r;

  /**
   * Diagonal element
   */
  persistent parallelise double   d;
  
  enum VertexType {
    Unknown, Dirichlet, Neumann
  };
  
  persistent VertexType vertexType;
  
  // some other attributes
};
\end{code}

\noindent
Besides a proper initialisation of the vertices, we extend the specification
similar to the heat equation.
\begin{code}
component: Multigrid

namespace: ::multigrid

vertex:
  dastgen-file: Vertex.def
  read scalar(double): U
  read scalar(double): R
  read scalar(double): D
  read scalar(double): F
  write scalar(double): U
  write scalar(double): R
  write scalar(double): D
  
...

adapter:
  name: CreateGrid
  merge-with-user-defined-mapping: CreateGrid
  merge-with-user-defined-mapping: PlotCells
  merge-with-predefined-mapping: VTKPlotVertexValue(u,getU,u)
\end{code}

\noindent
Once this code framework passes (only minor technical helper routines have to
be implemented, but by now this should be straightforward to any user), we can
introduce a new mapping/adapter \texttt{JacobiSmoother}, call this one a couple of hundred times in the runner and plot the result file then. 
For the latter, it makes sense to use a predefined plotter.
The interesting new aspects can be found in three routines of the smoother.
The design of the code realises matrix-free element-wise mat-vecs 1:1: 


\begin{enumerate}
  \item Each vertex carries a residual and a diagonal value attribute. 
    They are cleared whenever the vertex is read the very first time in
    a traversal.
    \begin{code}
void multigrid::mappings::JacobiSmoother::touchVertexFirstTime(...) {
  logTraceInWith6Arguments( "touchVertexFirstTime(...)", ... );

  fineGridVertex.clearAccumulatedAttributes();

  logTraceOutWith1Argument( "touchVertexFirstTime(...)", fineGridVertex );
}

// in Vertex files

void multigrid::Vertex::clearAccumulatedAttributes() {
  _vertexData.setR(0.0);
  _vertexData.setD(0.0);
}
    \end{code}
    
    \noindent
    Our concept is that we accumulate the diagonal element $d$ and the residual
    $r$ within these (temporary) attributes per vertex throughout the traversal.
    
    \item When we use a vertex for the very last time, we may thus update the
    unknown according to the values of the residual and the diagonal value. This
    is the actual Jacobi smoothing step:
    \[
      u ^{(new)} \gets u ^{(old)} + \omega \frac{1}{d} r
    \]
    \begin{code}
void multigrid::mappings::JacobiSmoother::touchVertexLastTime(...) {
  const bool hasUpdated = fineGridVertex.performJacobiSmoothingStep( omega );
  
  ...
}

// in Vertex files

double multigrid::Vertex::getResidual() const {
  return _vertexData.getF() + _vertexData.getR();
}


void multigrid::Vertex::performJacobiSmoothingStep( double omega ) {
  if (_vertexData.getVertexType()== Records::Unknown) {
    assertion1( _vertexData.getD()>0.0, toString() );
    assertion2( omega>0.0, toString(), omega );
    _vertexData.setU( _vertexData.getU() + omega / _vertexData.getD() * getResidual() );
  }
}
    \end{code} 
    
    \noindent
    Please note that the residual here is modelled as sum of the right-hand
    side and the accumulated value (cf.~helper operation
    \texttt{getResidual()}).
    We anticipate the minus from the definition 
    \[ r = f - Au \]
    already in the accumulation, i.e.~sum up $-Au$ in the vertex attribute $r$.
    An additional pitfal is this context stems from the usage of a finite
    element method.
    It implies that we have to ensure that $f$ is scaled with $h^d$ ($h$ being the local mesh width), which is something we typically
    do already in the initialisation. 
    
    \begin{remark}
    It is obvious that the Jacobi update scheme may only update inner
    unrefined vertices as well as Neumann boundary points. Peano does not offer
    vertex types. It distinguishes only inner and outer vertices. As we need
    more flags than inside and outside (at least two boundary
    flags), we have to offer these on our own\footnotemark .
    \end{remark}
    \footnotetext{Up to
    early 2016, Peano had a three-valued logic with inner, outer and boundary vertices. I
    removed this from the kernel as most applications need way more vertex
    types anyway.}
    
    
    In the present implementation, we make the Jacobi update return a flag that
    indicates whether a fine grid update has been done or not. 
    Most codes will like to track global data such as a global residual or the
    maximum value of the solution and can use this flag to decide whether a
    vertex contributes to global data or not. Please study the accompanying
    source code for details.
    
    \item The most complicated part is obviously the evaluation of the local
    mat-vec contributions. Here, we rely on the cell's
    \texttt{getElementsAssemblyMatrix} as well as operations from \newline
    \texttt{VertexOperations}. All operations in this class are generated by the
    PDT and extract from \texttt{enterCell}'s vertices vectors: you hand in all
    fine grid data and extract a vector of all $u$ values, e.g. The other way
    round is supported as well. The operations within this helper class are all
    generated because of the read and write statements in the specification. 
    \begin{code}
#include "multigrid/VertexOperations.h"

void multigrid::mappings::JacobiSmoother::enterCell(...) {
  logTraceInWith4Arguments( "enterCell(...)", fineGridCell, ... );

  const tarch::la::Vector<TWO_POWER_D,double> u    =
    VertexOperations::readU( fineGridVerticesEnumerator, fineGridVertices );
  const tarch::la::Vector<TWO_POWER_D,double> dOld    =
    VertexOperations::readD( fineGridVerticesEnumerator, fineGridVertices );
  const tarch::la::Vector<TWO_POWER_D,double> rOld =
    VertexOperations::readR( fineGridVerticesEnumerator, fineGridVertices );
  const matrixfree::stencil::ElementWiseAssemblyMatrix A =
    fineGridCell.getElementsAssemblyMatrix( fineGridVerticesEnumerator.getCellSize() );

  tarch::la::Vector<TWO_POWER_D,double> r = rOld - A * u;
  tarch::la::Vector<TWO_POWER_D,double> d = dOld + tarch::la::diag(A);

  VertexOperations::writeR( fineGridVerticesEnumerator, fineGridVertices, r );
  VertexOperations::writeD( fineGridVerticesEnumerator, fineGridVertices, d );

  logTraceOutWith1Argument( "enterCell(...)", fineGridCell );
}
    \end{code}
\end{enumerate}



\subsection{Environment}

The changes in the environment are straightforward once the smoother is 
in place:
\begin{enumerate}
  \item We extend the runner such that it switches to the Jacobi smoother once 
  the grid is set up and triggers a fixed number of iterations then.
  \item We add a logging device to the runner
  \begin{code}
    class multigrid::runners::Runner {
      private:
        static tarch::logging::Log  _log;
        ...
    };
  \end{code}
  and make the innermost loop plot residual and other statistics after each 
  grid traversal:
  \begin{code}
  repository.switchToJacobiAndPlot();
  for (int i=0; i<100; i++) {
    repository.iterate();

    logInfo(
      "runAsMaster(...)",
      "#vertices=" << repository.getState().getNumberOfInnerLeafVertices() <<
      ",|res|_2=" << repository.getState().getResidualIn2Norm() <<
      ",|res|_max=" << repository.getState().getResidualInMaxNorm() <<
      ",|u|_L2=" << repository.getState().getSolutionInL2Norm() <<
      ",|u|_max=" << repository.getState().getSolutionInMaxNorm() <<
      ",#stencil-updates=" << repository.getState().getNumberOfStencilUpdates()
    );

    repository.getState().clearAccumulatedAttributes();
  }
  \end{code}
  \item To make the code work, we augment the state with the corresponding
  fields 
  \begin{code}
Packed-Type: short int;

class multigrid::records::State {  
  // Stores squared value, i.e. apply sqrt before returning it
  persistent parallelise double residual2Norm;
  persistent parallelise double residualMaxNorm;
  // Stores squared value, i.e. apply sqrt before returning it
  persistent parallelise double solutionL2Norm;
  persistent parallelise double solutionMaxNorm;
  persistent parallelise double numberOfStencilUpdates;
};
  \end{code}
  and realise the corresponding setters and getters. The design of the state
  methods (notably a method \texttt{clearAccumulatedAttributes()} in
  combination with \texttt{merge}) follows recommendations motivated in Section
  \ref{section:parallelisation:shared-memory}. For the time being, we do not
  discuss them further.
  \item Finally, we extend the \texttt{main} such that it can read in a
  well-suited relaxation parameter from the command line. It then sets this
  relaxation parameter (the static field) in the mapping:
  \begin{code}
    multigrid::mappings::JacobiSmoother::omega = atof( argv[2] );
  \end{code}
\end{enumerate}


\noindent
We may run this code for example the
well-known Poisson benchmark ($\epsilon = 1, v=0, f=d\ \pi ^2 \prod _i \sin
\left( x_i \pi \right) $ ), and observe the well-known dependency of Jacobi on
the mesh width (below grids with two, three or four compute grid levels):

\begin{center}
  \includegraphics[width=0.3\textwidth]{42_matrix-free-multigrid/Poisson3.png}
  \includegraphics[width=0.3\textwidth]{42_matrix-free-multigrid/Poisson4.png}
  \includegraphics[width=0.3\textwidth]{42_matrix-free-multigrid/Poisson5.png}
\end{center}


\subsection{Dynamically adaptive Jacobi mit FAC}

\noindent 
We next implement a dynamically adaptive Jacobi solver that implements the FAC
scheme.
Its fundamental idea is that the Jacobi smootherr is applied on each and every
grid level in parallel.
Any hanging node's value is interpolated from coarser grids.
While we update all grid levels, we do overwrite coarse vertices with fine grid
values for all vertices that do exist on finer grid resolutions as well.
We inject the solution from the fine grids onto coarser grids.
This first solver is capable to handle dynamically adaptive grids with
arbitrary refinement pattern.
It also is a preliminary exercise how to implement multigrid full approximation
storage (FAS).

We extend the grid setup slightly such that it creates a very coarse grid even
if we prescribe a fine minimum mesh size.
Next, we validate that \texttt{enterCell} evaluates the stencil on each grid
level.
This leaves two tasks: interpolatation and injection.
The injection is basically the same we have used in the heat equation before.
\begin{code}
void multigrid::mappings::JacobiSmoother::touchVertexLastTime(...) {
 // see code snippets introduced before

 if (
  peano::grid::SingleLevelEnumerator::isVertexPositionAlsoACoarseVertexPosition(
    fineGridPositionOfVertex
  )
 ) {
  const peano::grid::SingleLevelEnumerator::LocalVertexIntegerIndex coarseGridPosition =
    peano::grid::SingleLevelEnumerator::getVertexPositionOnCoarserLevel
    (fineGridPositionOfVertex);
  coarseGridVertices[ coarseGridVerticesEnumerator(coarseGridPosition) ].inject(fineGridVertex);
 }
}


// in the vertex

void multigrid::Vertex::inject(const Vertex& fineGridVertex) {
  _vertexData.setU( fineGridVertex._vertexData.getU() );
}
\end{code}



\begin{remark}
  The \texttt{matrixfree} toolbox offers a type \texttt{solver::Smoother} that
  realises a Jacobi smoother that automatically tracks different residual and
  solution norms. In the present example we do not use this smoother while we
  use the toolbox's multigrid class. This is kind of inconsistent. It would
  probably be better to use the smoother as well.
\end{remark}

\noindent
The interpolation follows the idea of the heat equation solver, too.
However, we propose to rely on a premanufactured interpolation operation from
the \texttt{matrixfree} toolbox.
For this, we make our smoother mapping hold an instance of
\texttt{matrixfree::solver::Multigrid  \_multigrid}.
This object offers us an operation \texttt{getDLinearInterpolatedValue}: 

\begin{code}
void multigrid::mappings::JacobiSmoother::createHangingVertex(...) {
  logTraceInWith6Arguments( "createHangingVertex(...)", ... );

  fineGridVertex.setU(
    _multigrid.getDLinearInterpolatedValue(
      VertexOperations::readU( coarseGridVerticesEnumerator, coarseGridVertices ),
      fineGridPositionOfVertex
    )
  );

  logTraceOutWith1Argument( "createHangingVertex(...)", fineGridVertex );
}
\end{code}


\noindent
Obviously, the vertex requires an additional \texttt{setU( double )} operation
to make this snippet work.
Its implementation is trivial.
This is the only additional extension required.
If we adopt the setup, we might solve the equation on grids alike below where
the mesh is resolved up to the finest level along the boundaries. 
The latter is a proper choice for many problems, though inadequate and thus
only a proof of concept for the present case:

\begin{center}
  \includegraphics[width=0.3\textwidth]{42_matrix-free-multigrid/AdaptivePoisson3.png}
  \includegraphics[width=0.3\textwidth]{42_matrix-free-multigrid/AdaptivePoisson4.png}
\end{center}



\begin{remark}
  On some machines, the resulting code will fail in \texttt{Assert} mode as the
  plotters complain about nan for the right-hand side. In the release
  mode, i.e.~without assertions, no complaint is raised, but some visualisation
  software might complain about the nans. To fix this issue with the plotting,
  it is important to set the right-hand side $f$ to zero for hanging nodes and
  for boundary nodes. We propose to introduce a \texttt{clearF()} operation and
  to call it prior to any plotting (in the \texttt{CreateGrid} mapping for
  example) for hanging and boundary vertices.
\end{remark}

\noindent
We close our discussion on the Jacobi smoother with the introducton of a dynamic
refinement criterion.
For this, we rely on a predefined refinement criterion offered with the
matrixfree toolbox.
We use
\texttt{LinearSurplusRefinementCriterionWithFixedMeshSizes}
from \\
\texttt{matrixfree::adaptivitycriteria}.
There is an extensive documentation how to use it in its superclass' header, so
we do not reiterate this here.
Instead we just show some of the added code:

\begin{code}
multigrid::mappings::RefinementCriterion::RefinementCriterion():
  _refinementCriterion(
    0.1,                   // refinementPercentage,
    0.0,                   // deletePercentage,
    0.5,                   // minimumMeshSize,
    0.5                    // maximumMeshSize
  ) {
}

void multigrid::mappings::RefinementCriterion::touchVertexFirstTime(...) {
  VertexOperations::writeLinearSurplus(fineGridVertex,0.0);
}

void multigrid::mappings::RefinementCriterion::enterCell(...) {
  VertexOperations::writeLinearSurplus(
    fineGridVerticesEnumerator,
    fineGridVertices,
    _refinementCriterion.getNewLinearSurplus(
      VertexOperations::readU(fineGridVerticesEnumerator,fineGridVertices),
      VertexOperations::readLinearSurplus(fineGridVerticesEnumerator,fineGridVertices)
    )
  );
}

void multigrid::mappings::RefinementCriterion::touchVertexLastTime(...) {
  if ( fineGridVertex.isInside() ) {
    const tarch::la::Vector<TWO_POWER_D_TIMES_D,double > coarseGridLinearSurplus =
      VertexOperations::readLinearSurplus(coarseGridVerticesEnumerator, coarseGridVertices)
      +
      _refinementCriterion.getLinearSurplusContributionFromFineGrid(
        VertexOperations::readLinearSurplus( fineGridVertex ),
        fineGridVertex.getRefinementControl()==Vertex::Records::Unrefined,
        fineGridPositionOfVertex
      );

    VertexOperations::writeLinearSurplus( coarseGridVerticesEnumerator, 
      coarseGridVertices, coarseGridLinearSurplus );

    switch (
      _refinementCriterion.analyse(
        VertexOperations::readLinearSurplus(fineGridVertex),
        fineGridVertex.getRefinementControl()==Vertex::Records::Refined,
        fineGridVertex.getRefinementControl()==Vertex::Records::Unrefined,
        fineGridH
      )
    ) {
      case matrixfree::adaptivitycriteria::LinearSurplusRefinementCriterion::Refine:
        fineGridVertex.refine();
        break;
      case matrixfree::adaptivitycriteria::LinearSurplusRefinementCriterion::Delete:
      case matrixfree::adaptivitycriteria::LinearSurplusRefinementCriterion::NoAction:
        break;
    }
  }
}
\end{code}

\noindent
The criterion's idea is to evaluate a stencil that allows us to compare the
linear interpoland of the solution within a vertex to the actual vertex's
solution value.
We anticipate what would happen if we could remove a particular vertex alone.
The other way round, we assume that vertices with a big difference are critical,
and we would benefit a lot if we would refine around this vertex.

The offered criterion class bucket sorts the linear surplus values. This is not
exact, but it does not require a real sort being in $\mathcal{O}(n \log
n)$---actually nothing is sorted, but each bucket is flagged (refine, coarse,
do nothing).
If a vertex falls into a particular bucket, the criterion returns the
corresponding flag.
More sophisticated criteria might yield better approximation patterns, but this
generic one works surprisingly well.

\begin{center}
  \includegraphics[width=0.24\textwidth]{42_matrix-free-multigrid/DynamicA00.png}
  \includegraphics[width=0.24\textwidth]{42_matrix-free-multigrid/DynamicA01.png}
  \includegraphics[width=0.24\textwidth]{42_matrix-free-multigrid/DynamicA02.png}
  \includegraphics[width=0.24\textwidth]{42_matrix-free-multigrid/DynamicA03.png}
\end{center}

\noindent
This code marks up to ten percent of the vertices for refinemenet and
consequently refines all the surrounding cells given that the residual in
the vertices underruns the given threshold \\
\texttt{\_convergenceThreshold}.
The latter magic constant is set to $10^{-2}$ for the plots above.

Now, one simple feature is worth trying: We have so far always used a
predefined visualisation routine that visualises the finest grid of a
simulation.
Among the set of standard visualisation routines also is a plotter that plots
the individual levels of a grid.
Given that we inject the solution to coarse levels anyway, this allows us to
visualise all data in a multilevel fashion.
To use it, we again extend our specification, regenerate the glue code and
recompile.

\begin{code}
adapter:
  name: JacobiAndPlot
  merge-with-user-defined-mapping: CreateGrid
  merge-with-user-defined-mapping: JacobiSmoother
  merge-with-user-defined-mapping: PlotCells
  merge-with-predefined-mapping: VTKPlotVertexValue(u,getU,u)
  merge-with-predefined-mapping: VTKPlotVertexMultilevelValue(multiscaleU,getU,u)
\end{code}

\noindent
Some minor remarks on proper initialisation that are often encountered shall
close the discussion.
First, the presented refinement criterion does not properly refine along the
domain's boundary, as it does not distinguish whether a stencil is applied along
the boundary. 
In practice, it is reasonable to ensure that the boundary is always refined at
least as fine as the vertices next to the boundary. 
In practive, it is reasonable to avoid hanging vertices along the boundary. 
This can be achieved if we check within each cell whether there is a boundary
vertex and whether one vertex is refined.
If both properties hold, all unrefined boundary vertices have to be refined. 
The class \texttt{peano::grid::aspects::VertexStateAnalysis} provides generic
helper routines to realise this behaviour with a few lines:

\begin{code}
#include "peano/grid/aspects/VertexStateAnalysis.h"
#include "peano/utils/Loop.h"

void multigrid::mappings::RefinementCriterion::enterCell(...) {
  ...
  if (
    fineGridCell.isRefined()
    &&
    peano::grid::aspects::VertexStateAnalysis::doesOneVertexCarryRefinementFlag(
      fineGridVertices, fineGridVerticesEnumerator, Vertex::Records::Unrefined
    )
  ) {
    bool isOneVertexABoundaryVertex = false;
    dfor2(k)
      isOneVertexABoundaryVertex |= 
        fineGridVertices[ fineGridVerticesEnumerator(k) ].isBoundary();
    enddforx
    if (isOneVertexABoundaryVertex) {
      dfor2(k)
        if (fineGridVertices[ fineGridVerticesEnumerator(k) ].getRefinementControl()
          ==Vertex::Records::Unrefined) {
          fineGridVertices[ fineGridVerticesEnumerator(k) ].refine();
        }
      enddforx
    }
  }
 
}
\end{code}

\noindent
Second, many codes require a proper balancing. 
As Peano relies on three-partitioning, a 3:1 balancing is something many codes
would like to have: 
No two neighbouring cells differ in their maximum refinement level by more than
one.
This can be realised manually within a mapping. 
Or you may decide to merge the predefined mapping \texttt{GridBalancer3to1} into 
your adapters. 



Finally, any dynamically adaptive code should properly initialise new vertices. 
In the present example, a proper initialisation could rely on $d$-linear
interpolation again.
For multigrid, higher order schemes are desireable (though in practice I again
observed that linear interpolation is sufficient), but higher order
interpolation then has to be realised manually with helper variables or some
additional code applying the stencil to newly generated vertices.
We stick to the linear case here:
\begin{code}
void ...::createInnerVertex(...) {
  fineGridVertex.setU(
    _multigrid.getDLinearInterpolatedValue(
      VertexOperations::readU( coarseGridVerticesEnumerator, coarseGridVertices ),
      fineGridPositionOfVertex
    )
  );
}
\end{code}


\begin{center}
  \includegraphics[width=0.34\textwidth]{42_matrix-free-multigrid/DynamicB.png}
  \includegraphics[width=0.45\textwidth]{42_matrix-free-multigrid/MultiLevel.png}
\end{center}

\noindent
The right image above presents the result of the multilevel plotter:
Each grid resolution level is written to a separate file.
It is obvious that finer grid solution approximations overwrite coarser vertex
values, while the coarse values determine the hanging node values.
We also see that the grid is refined towards the boundary here.



\subsection{Multigrid}

We start with some metaphilosophical considerations.
Multigrid algorithms work in two types of spaces: the ansatz
(discretisation) space holding the solution and a set of correction spaces.
The latter either are updated all at once (additive multigrid) or one after
another (multiplicative) before their contribution is added back to the actual
representation.
In the present discussion, we restrict ourselves to geometrically inspired
multigrid where both the correction and the discretisation space are spanned by
the spacetree's grid levels.
On the previous pages, we have realised a Jacobi directly within the
discretisation space without assembling any bigger matrix.
Obviously, such an approach also works for the correction equations.



At first glance, we then however need two variable sets per vertex: one set for
the actual discretisation and one for the correction equations.
As long as we work on regular grids only, there is no need to store different
types of variables within the vertices: refined vertices hold correction
equations, fine grid vertices hold the discretisation.
This approach becomes problematic for adaptive grids. 
Still, unrefined vertices of the fine grid hold the discretised PDE. 
On the same level of an arbitrary unrefined level, there might however also be
an area that is refined further.
Here, we solve a correction equation. 
If we realised both the correction equation and the discretisation with the same
set of variables, what would the right vertex values at the transition between
unrefined and correction areas be? 
We have to distinguish carefully in each cell which type of equation we are
solving, unless \ldots


\ldots we solve also the correction equation in a discretisation space. This is
the idea of full approximation storage (FAS) which fits perfectly to our
injection that we realised anyway. Instead of solving
\[ 
  A_{3h} e = \hat f 
\]
in areas that are refined further and thus hold a correction to the actual
solution iterate, we solve
\begin{eqnarray*}
  A_{3h} \left( Iu_h + e \right)  & = & \hat f +  A_{3h} Iu_h \qquad \mbox{added
  an additional term on both sides} \\
  & = & R r_h + RA_hPIu_h \\
  & = & R \left( r_h + A_hPIu_h \right) \\
  & = & R \left( f_h - A_hu_h + A_hPIu_h \right) \\
  & = & R \left( f_h - A_h\left( id - PI\right)u_h \right) \\
  & =: & R \left( f_h - A_h \hat u_h \right)  =: R \hat r_h  
\end{eqnarray*}
i.e.~work with a coarsened solution as input to the correction solve 
which is a formalism introduced by Griebel as HTMG.


So we can stick to our injections of the solution. 
In each traversal, we have to determine the hierarchical surplus in each vertex
$\hat u = u - PIu_h$ which is simple, as $Iu_h$ is available anyway.
This hierarchical transform is a temporary helper. 
We can throw it away after the traversal again.
We can model it as \texttt{discard} in the \texttt{Vertex.def}.

Once we have $\hat u$, we can simultaneously determine the residual $r$ as well
as its hierarchical counterpart $\hat r$. 
With the residual $r$, we update the solution if we have to---a detail subject
of discussion in a minute when we finalise whether to realise a multiplicative
or additive scheme.
The hierarchical residual $\hat r$ in turn is not used to update any solution
directly.
It is restricted to the next coarser level to yield a right-hand side there.


We finally observe that we may not just update the solution with the residual.
If we did that we would loose the knowledge which correction to prolong to the
next finer level.
We therefore store the updates in another helper variable and use this update to
prolong it to a finer level later on.

\begin{remark}
  The update helper variable is not the only valid choice to
  distinguish coarse grid updates from fine grid representation. It is obviously
  that we also might store the hierarchical surplus persistently and then
  reconstruct the nodal value with the relation $u_h=\hat u_h+Pu_{3h}$. This is
  the implementation variant discussed in (Weinzierl:09), while a more detailed
  analysis of required helper variables for additive multigrid can be found in
  (Reps:16).
\end{remark}



\begin{code}
class multigrid::records::Vertex {  
  persistent parallelise double  u;             // Solution
  persistent parallelise double  f;             // Rhs
  discard parallelise double     r;             // Residual
  discard parallelise double     d;             // Diagonal element
  discard parallelise double     hierarchicalU; // Hierarchical solution
  discard parallelise double     hierarchicalR; // Hierarchical residual
  persistent parallelise double  uUpdate;       // Update of solution
  discard parallelise double     linearSurplus[DIMENSIONS];

  enum VertexType {
    Unknown, Dirichlet, Neumann
  };
  persistent VertexType vertexType;
};
\end{code}


\noindent
The hierarchical surplus has to be determined in \texttt{touchVertexFirstTime}
where we also clear the temporary variables.
I decided to realise the generic multigrid operations in a mapping of its own. 
It is called \texttt{HierarchicalTransformAndRHSRestriction}.
Once more, we rely on an instance of the Multigrid class.

\begin{code}
void
multigrid::mappings::HierarchicalTransformAndRHSRestriction::createHangingVertex(...) { 
 fineGridVertex.clearHierarchicalValues();
}

void multigrid::mappings::HierarchicalTransformAndRHSRestriction::touchVertexFirstTime(...) {
 fineGridVertex.clearHierarchicalValues();

 if ( fineGridVertex.isInside() ) {
   const tarch::la::Vector<TWO_POWER_D,double > u_3h  = 
     VertexOperations::readU(coarseGridVerticesEnumerator,coarseGridVertices);
   const tarch::la::Vector<TWO_POWER_D,double > e_3h  = 
     VertexOperations::readUUpdate(coarseGridVerticesEnumerator,coarseGridVertices);
   const double                                 Pu_3h = 
     _multigrid.getDLinearInterpolatedValue(u_3h,fineGridPositionOfVertex);
   const double                                 Pe_3h =
     _multigrid.getDLinearInterpolatedValue(e_3h,fineGridPositionOfVertex);

   fineGridVertex.correctU(Pe_3h);
   fineGridVertex.determineUHierarchical(Pu_3h);

   if (fineGridVertex.getRefinementControl()!=Vertex::Records::Unrefined) {
     fineGridVertex.clearF();
   }
 }

 fineGridVertex.clearAccumulatedAttributes();
}

void multigrid::Vertex::determineUHierarchical(double Pu_3h) {
  _vertexData.setHierarchicalU( _vertexData.getU()-Pu_3h );
}
\end{code}


\begin{remark}
  In this presentation, we make the solvers restrict residuals on all levels all
  the time and prolong all updates all the time.
  The actual distinction between additive and multiplicative multigrid stems from the decision which
  level is smoothed, i.e.~where we find an update. This is
  highly inefficient.
  Good solvers would compute only those residuals and right-hand sides that have changed and
  are required. But the purpose of this presentation is to introduce a quick,
  brief prototype. Speed is a different topic.
\end{remark}

\noindent
The accumulation of the hierarchical surplus itself is more or less a
cut-n-paste from the Jacobi smoother:
\begin{code}

void multigrid::mappings::HierarchicalTransformAndRHSRestriction::enterCell(...) { 
  const tarch::la::Vector<TWO_POWER_D,double> hierarchicalU    =
     VertexOperations::readHierarchicalU( fineGridVerticesEnumerator, fineGridVertices );
   const tarch::la::Vector<TWO_POWER_D,double> hierarchicalROld =
     VertexOperations::readHierarchicalR( fineGridVerticesEnumerator, fineGridVertices );
   const matrixfree::stencil::ElementWiseAssemblyMatrix A =
     fineGridCell.getElementsAssemblyMatrix( fineGridVerticesEnumerator.getCellSize() );

   tarch::la::Vector<TWO_POWER_D,double> hierarchicalR = 
     hierarchicalROld - A * hierarchicalU;

   VertexOperations::writeHierarchicalR
     ( fineGridVerticesEnumerator, fineGridVertices, hierarchicalR );
}
\end{code}

\noindent 
For the restriction, we again rely on the multigrid object, where a specialised
prolongation function does exist that uses $d$-linear interpolation.
Furthermore, we stick to the convention $R=P^T$ and thus can write:

\begin{code}
void
multigrid::mappings::HierarchicalTransformAndRHSRestriction::touchVertexLastTime(...) {
  if ( fineGridVertex.isInside() ) {
    const tarch::la::Vector<TWO_POWER_D, double > P = 
      _multigrid.calculateP(fineGridPositionOfVertex);

    dfor2(k)
      // There is no need to exclude boundary points here (the rhs does not play
      // there a role anyway), but it makes the visualisation nicer.
      if (
        coarseGridVertices[ coarseGridVerticesEnumerator(k) ].getRefinementControl()==
          Vertex::Records::Refined
        &&
        coarseGridVertices[ coarseGridVerticesEnumerator(k) ].isInside()
      ) {
        coarseGridVertices[ coarseGridVerticesEnumerator(k) ].incF(  
          P(kScalar) * fineGridVertex.getHierarchicalResidual() 
        );
      }
    enddforx
  }
}

void multigrid::Vertex::incF(double value) {
  _vertexData.setF( _vertexData.getF()+value );
}

double multigrid::Vertex::getHierarchicalResidual() const {
  return _vertexData.getF() + _vertexData.getHierarchicalR();
}
\end{code}


\noindent
We close the preparatory work with the remark that the specification has to be
augmented by additional readers and writers to make our code snippets work:

\begin{code}
component: Multigrid

namespace: ::multigrid

vertex:
  dastgen-file: Vertex.def
  read scalar(double): U
  read scalar(double): F
  read scalar(double): R
  read scalar(double): D
  read scalar(double): HierarchicalU
  read scalar(double): HierarchicalR
  write scalar(double): U
  write scalar(double): R
  write scalar(double): D
  write scalar(double): HierarchicalU
  write scalar(double): HierarchicalR

...
\end{code}

\begin{center}
  \includegraphics[width=0.8\textwidth]{42_matrix-free-multigrid/Hierarchical-Jacobi.png}
\end{center}

\noindent
We see above a Jacobi smoother (100 iterations) for the Poisson equation on the
unit square (left) as well as the hierarchical representation (right).
We also may augment the adapters with plots of the temporary data 

\begin{code}
adapter:
  name: AnyAdapter
  ...
  merge-with-predefined-mapping: VTKPlotVertexValue(u,getU,u)
  merge-with-predefined-mapping: VTKPlotVertexMultilevelValue(multiscaleU,getU,u)
  merge-with-predefined-mapping: VTKPlotVertexMultilevelValue
    (multiscaleHierarchicalU,getHierarchicalU,u)
  merge-with-predefined-mapping: VTKPlotVertexMultilevelPointCloud
    (multiscaleResidual,getResidual,res)
  merge-with-predefined-mapping: VTKPlotVertexMultilevelPointCloud
    (multiscaleHierarchicalResidual,getHierarchicalResidual,res)
  merge-with-predefined-mapping: VTKPlotVertexMultilevelPointCloud(f,getF,f)
\end{code}

\noindent
and emphasise that we basically have almost all multigrid ingredients at hands.
Missing is a projection from coarse grid updates to fine grid values.
So far, we update the coarse grid values according to the right-hand side.
These updates however are not projected.
Instead, the updated approximation in a FAS sense are overwritten at the end of
the subsequent iteration with fine grid solution data. 


\begin{remark}
  Most default VTK plotters plot the grid as well as values and (for
  consistency reasons imposed by the VTK data file format) have to plug into
  \texttt{touchVertexFirstTime}. For residuals and other temporary data, we
  typically however are interested to plot the value at the end of the
  iteration. A quick solution here is to plot the grid with one mapping and to
  use a second mapping that solely plots a point cloud with the vertex values.
  We then can visualise both data sets simultaneously.
\end{remark}





\subsection{Additive Geometric Multigrid}

In additive multigrid, we may not use the same relaxation factor on each and
every level. 
Instead, it is important that the coarser the level the smaller the contribution
to the solution update.
Otherwise, the solver tends to overshoot and become unstable. 
We propose to use relaxation factors $\omega ^k$ with $k=1$ on the fine grid
level and increasing by one for each level up the hierarchy.
$\omega $ obviously has to be adopted if the grid changes.
It is thus straightforward to compute it on-the-fly. 
For this, we add an additional variable to the vertex

\begin{code}
class multigrid::records::Vertex {  
  persistent parallelise int  numberOfFinerLevelsAtSamePosition;
};
\end{code}

\noindent
and make the grid traversal determine the correct value of this attribute
on the fly:



void multigrid::Vertex::clearAccumulatedAttributes() {
  _vertexData.setR(0.0);
  _vertexData.setD(0.0);
  
  _vertexData.setNumberOfFinerLevelsAtSamePosition( 1 );
}


void multigrid::mappings::AdditiveMGProlongation::touchVertexFirstTime(
  multigrid::Vertex&               fineGridVertex,
  const tarch::la::Vector<DIMENSIONS,double>&                          fineGridX,
  const tarch::la::Vector<DIMENSIONS,double>&                          fineGridH,
  multigrid::Vertex * const        coarseGridVertices,
  const peano::grid::VertexEnumerator&                coarseGridVerticesEnumerator,
  multigrid::Cell&                 coarseGridCell,
  const tarch::la::Vector<DIMENSIONS,int>&                             fineGridPositionOfVertex
) {
  logTraceInWith6Arguments( "touchVertexFirstTime(...)", fineGridVertex, fineGridX, fineGridH, coarseGridVerticesEnumerator.toString(), coarseGridCell, fineGridPositionOfVertex );

  if (fineGridVertex.isInside()) {
    const tarch::la::Vector<TWO_POWER_D,double > e_3h  = VertexOperations::readUUpdate(coarseGridVerticesEnumerator,coarseGridVertices);
    const double                                 Pe_3h = _multigrid.getDLinearInterpolatedValue(e_3h,fineGridPositionOfVertex);

    fineGridVertex.correctU(
      Pe_3h
      *
      fineGridVertex.getDampingFactorForAdditiveCoarseGridCorrection(multigrid::mappings::JacobiSmoother::omega)
    );
  }

  // hier muss ich auch noch die Level beruecksichtigen. Das kann aber innerhalb der Vertex erfolgen.

  logTraceOutWith1Argument( "touchVertexFirstTime(...)", fineGridVertex );
}


Update doch spezifisch



inject ein bischen falsch. Eigentlich besser R. 

@todo Instabil. Relaxation mit aufnehmen

@todo Kleiner Fehler mit der Injektion. Auf Bram verweisen, aber so lassen







\subsection{Multiplicative Geometric Multigrid}

V2,2?




\subsection*{Further reading}

\begin{itemize}
  \item  Reps, Bram and Weinzierl, Tobias: {\em Complex additive geometric
  multilevel solvers for Helmholtz equations on spacetrees}, tech report,  
  arXiv:1508.03954
  \item Weinzierl, Marion: {\em Hybrid Geometric-Algebraic Matrix-Free Multigrid on
Spacetrees}, Dissertation, Technische Universit\"at M\"unchen, 2013
  \item   Muntean, Ioan Lucian, Mehl, Miriam, Neckel, Tobias and Weinzierl,
  Tobias (2008). {\em Concepts for Efficient Flow Solvers Based on Adaptive
  Cartesian Grids}. In High Performance Computing in Science and Engineering, Garching 2007. Wagner, Siegfried, Steinmetz, Matthias, Bode, Arndt & Brehm, Matthias Berlin Heidelberg New York: Springer.
  \item Weinzierl, Tobias and K\"oppl, Tobias (2012). {\em A Geometric
  Space-time Multigrid Algorithm for the Heat Equation}. Numerical Mathematics:
  Theory, Methods and Applications 5(1): 110-130.
  \item Mehl, Miriam, Weinzierl, Tobias and Zenger, Christoph (2006). {\em A
  cache-oblivious self-adaptive full multigrid method}. Numerical Linear Algebra
  with Applications 13(2-3): 275-291.
\end{itemize}
