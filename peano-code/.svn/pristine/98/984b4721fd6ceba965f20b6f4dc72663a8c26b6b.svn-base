#ifdef SharedOMP
#include <omp.h>
#endif

#include "peano/datatraversal/autotuning/Oracle.h"
#include "tarch/multicore/MulticoreDefinitions.h"
#include "peano/utils/PeanoOptimisations.h"
#include "peano/performanceanalysis/Analysis.h"


template <class LoopBody>
tarch::logging::Log peano::datatraversal::ActionSetTraversalLoop<LoopBody>::_log( "peano::datatraversal::ActionSetTraversalLoop" );


template <class LoopBody>
peano::datatraversal::ActionSetTraversalLoop<LoopBody>::ActionSetTraversalLoop(
  peano::datatraversal::ActionSetTraversal traversal,
  LoopBody&                                loopBody,
  int                                      grainSize
) {
  #if defined(SharedMemoryParallelisation)
  if (grainSize>0) {
    loopParallel(traversal, loopBody, grainSize);
  }
  else {
    loopSequential(traversal, loopBody);
  }
  #else
  loopSequential(traversal, loopBody);
  #endif
}



template <class LoopBody>
void peano::datatraversal::ActionSetTraversalLoop<LoopBody>::loopSequential(
  const peano::datatraversal::ActionSetTraversal&  traversal,
  LoopBody&                                        loopBody
) {
  const int maximumPath = traversal.getMaximumPath();
  for (int currentStepInPath=0; currentStepInPath<maximumPath; currentStepInPath++ ) {
    peano::performanceanalysis::Analysis::getInstance().changeConcurrencyLevel(0,traversal.getActionSet(currentStepInPath).getNumberOfParallelActions());
    for (int j=0; j<traversal.getActionSet(currentStepInPath).getNumberOfParallelActions(); j++) {
      #ifdef CompilerICC
      #pragma forceinline
      #endif
      loopBody(traversal.getActionSet(currentStepInPath).getAction(j));
    }
    peano::performanceanalysis::Analysis::getInstance().changeConcurrencyLevel(0,-traversal.getActionSet(currentStepInPath).getNumberOfParallelActions());;
  }
}


template <class LoopBody>
void peano::datatraversal::ActionSetTraversalLoop<LoopBody>::loopParallel(
  const peano::datatraversal::ActionSetTraversal&  traversal,
  const LoopBody&                                  loopBody,
  int                                              grainSize
) {
  const int maximumPath = traversal.getMaximumPath();
  for (int currentStepInPath=0; currentStepInPath<maximumPath; currentStepInPath++ ) {
    peano::performanceanalysis::Analysis::getInstance().changeConcurrencyLevel(traversal.getActionSet(currentStepInPath).getNumberOfParallelActions()/grainSize,traversal.getActionSet(currentStepInPath).getNumberOfParallelActions());
    #ifdef SharedTBB
    ActionSetTraversalLoopInstance loopInstance(loopBody,traversal.getActionSet(currentStepInPath));
    tbb::parallel_reduce(
      tbb::blocked_range<int>(0,traversal.getActionSet(currentStepInPath).getNumberOfParallelActions(),grainSize),
      loopInstance
    );
    #elif SharedOMP
    // This check is due to a bug in the OpenMP-Library on Shaheen, which does not handle the case grainSize > problemSize correctly
    if(grainSize < traversal.getActionSet(currentStepInPath).getNumberOfParallelActions()) {
      LoopBody localIterationLoopBody(loopBody);

      #warning @Vasco OpenMP Implementierung evtl. nicht mehr up-to-date

      #pragma omp parallel
      {
        #pragma omp for schedule(dynamic, grainSize) firstprivate(localIterationLoopBody)
        for (int j = 0; j < traversal.getActionSet(currentStepInPath).getNumberOfParallelActions(); j++) {
          localIterationLoopBody(traversal.getActionSet(currentStepInPath).getAction(j));
        }
      }
    } else {
      LoopBody localIterationLoopBody(loopBody);
      for (int j = 0; j < traversal.getActionSet(currentStepInPath).getNumberOfParallelActions(); j++) {
        localIterationLoopBody(traversal.getActionSet(currentStepInPath).getAction(j));
      }
    }
    #else
    assertion(false);
    #endif
    peano::performanceanalysis::Analysis::getInstance().changeConcurrencyLevel(-traversal.getActionSet(currentStepInPath).getNumberOfParallelActions()/grainSize,-traversal.getActionSet(currentStepInPath).getNumberOfParallelActions());
  }
}


#ifdef SharedCobra
template <class LoopBody>
void peano::datatraversal::ActionSetTraversalLoop< LoopBody >::realiseParallelForAsTaskBipartitioning(
  ::cobra::blocked_range<int>                     range,
  ::cobra::continuator&                           ctr,
  const peano::datatraversal::ActionSet&  actionSet,
  const LoopBody&                                 loopBody
) {
  if (range.is_divisible()) {
    ::cobra::blocked_range<int>  range1, range2;
    range.split(range1, range2);
    ctr.fork<0>([=](::cobra::continuator &ctr){realiseParallelForAsTaskBipartitioning(range1, ctr, actionSet, loopBody);});
    ctr.fork<1>([=](::cobra::continuator &ctr){realiseParallelForAsTaskBipartitioning(range2, ctr, actionSet, loopBody);});
    ctr.join([]{});
  }
  else {
    LoopBody localIterationLoopBody(loopBody);
    for (int i=range.begin(); i!=range.end(); i++) {
      localIterationLoopBody(actionSet.getAction(i));
    }
  }
}
#endif


#ifdef SharedTBB
template <class LoopBody>
peano::datatraversal::ActionSetTraversalLoop<LoopBody>::ActionSetTraversalLoopInstance::ActionSetTraversalLoopInstance(
  const LoopBody&                         loopBody,
  const peano::datatraversal::ActionSet&  actionSet
):
  _loopBody(loopBody),
  _actionSet(actionSet) {
}


template <class LoopBody>
peano::datatraversal::ActionSetTraversalLoop<LoopBody>::ActionSetTraversalLoopInstance::ActionSetTraversalLoopInstance(
  const ActionSetTraversalLoopInstance&  copy,
  tbb::split
):
  _loopBody(copy._loopBody),
  _actionSet(copy._actionSet) {
}


template <class LoopBody>
void peano::datatraversal::ActionSetTraversalLoop<LoopBody>::ActionSetTraversalLoopInstance::operator() (const tbb::blocked_range<int>& range) {
  assertion( range.begin() >= 0 );
  assertion( range.end() <= _actionSet.getNumberOfParallelActions() );

  for (int i=range.begin(); i!=range.end(); i++) {
    _loopBody(_actionSet.getAction(i));
  }
}


template <class LoopBody>
void peano::datatraversal::ActionSetTraversalLoop<LoopBody>::ActionSetTraversalLoopInstance::join(const ActionSetTraversalLoopInstance&  with) {
}
#endif
