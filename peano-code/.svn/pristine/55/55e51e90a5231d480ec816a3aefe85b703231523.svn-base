#include "peano/datatraversal/dForLoop.h"
#include "peano/MappingSpecification.h"
#include "peano/datatraversal/autotuning/KernelGrainSizes.h"
#include "peano/datatraversal/autotuning/Oracle.h"


template <class Vertex, class Cell, class State, class EventHandle>
tarch::logging::Log  peano::grid::nodes::tasks::Ascend<Vertex,Cell,State,EventHandle>::_log( "peano::grid::nodes::tasks::Ascend" );


template <class Vertex, class Cell, class State, class EventHandle>
tarch::multicore::BooleanSemaphore  peano::grid::nodes::tasks::Ascend<Vertex,Cell,State,EventHandle>::_semaphore;


template <class Vertex, class Cell, class State, class EventHandle>
peano::grid::nodes::tasks::Ascend<Vertex,Cell,State,EventHandle>::Ascend(
  const int              treeDepth,
  State&                 state,
  EventHandle&           eventHandle,
  RegularGridContainer&  gridContainer
):
  _treeDepth( treeDepth ),
  _state(state),
  _eventHandle( eventHandle ),
  _gridContainer( gridContainer ),
  _treeRemainsStatic( true ),
  _touchVertexLastTimeLoopBody( _treeDepth, _eventHandle, _gridContainer, _treeRemainsStatic ),
  _leaveCellLoopBody( _eventHandle, _gridContainer ),
  _ascendLoopBody(_eventHandle, _gridContainer ) {
  assertion( treeDepth>=1 );
}


template <class Vertex, class Cell, class State, class EventHandle>
void peano::grid::nodes::tasks::Ascend<Vertex,Cell,State,EventHandle>::touchVerticesLastTime(int level) {
  bool runOperation =
    (_eventHandle.touchVertexLastTimeSpecification().manipulates == peano::MappingSpecification::WholeTree) ||
    (_eventHandle.touchVertexLastTimeSpecification().manipulates == peano::MappingSpecification::OnlyLeaves && level == _treeDepth);

  if (runOperation) {
    assertionMsg( _eventHandle.touchVertexLastTimeSpecification().multithreading != peano::MappingSpecification::AvoidFineGridRaces, "avoid fine grid races not supported. Use avoid coarse grid races instead" );


    const tarch::la::Vector<DIMENSIONS,int> NumberOfVertices      = _gridContainer.getNumberOfVertices(level);
    const int                               sharedMemoryGrainSize =
      _eventHandle.touchVertexLastTimeSpecification().multithreading == peano::MappingSpecification::Serial ? 0 :
      peano::datatraversal::autotuning::Oracle::getInstance().parallelise(
        _eventHandle.touchVertexLastTimeSpecification().multithreading == peano::MappingSpecification::RunConcurrentlyOnFineGrid ?
          tarch::la::volume(NumberOfVertices) : tarch::la::volume(NumberOfVertices) / SEVEN_POWER_D,
        peano::datatraversal::autotuning::CallTouchLastTimeOnRegularStationaryGrid
      );
    _touchVertexLastTimeLoopBody.setLevel( level );
    peano::datatraversal::dForLoop<TouchVertexLastTimeLoopBody>( NumberOfVertices, _touchVertexLastTimeLoopBody, sharedMemoryGrainSize, _eventHandle.touchVertexLastTimeSpecification().multithreading != peano::MappingSpecification::RunConcurrentlyOnFineGrid );

    if (_eventHandle.touchVertexLastTimeSpecification().multithreading != peano::MappingSpecification::Serial) {
      peano::datatraversal::autotuning::Oracle::getInstance().parallelSectionHasTerminated(peano::datatraversal::autotuning::CallTouchLastTimeOnRegularStationaryGrid);
    }
  }

  _gridContainer.haveCalledAllEventsOnThisLevel(level);
}



template <class Vertex, class Cell, class State, class EventHandle>
void peano::grid::nodes::tasks::Ascend<Vertex,Cell,State,EventHandle>::leaveCells(int level) {
  const bool runOperation =
    (_eventHandle.leaveCellSpecification().manipulates == peano::MappingSpecification::WholeTree) ||
    (_eventHandle.leaveCellSpecification().manipulates == peano::MappingSpecification::OnlyLeaves && level == _treeDepth);

  if (runOperation) {
    const tarch::la::Vector<DIMENSIONS,int> NumberOfCells = _gridContainer.getNumberOfCells(level);

    _leaveCellLoopBody.setLevel( level );

    switch (_eventHandle.leaveCellSpecification().multithreading) {
      case peano::MappingSpecification::Serial:
        {
          peano::datatraversal::dForLoop<LeaveCellLoopBody> loop(
            NumberOfCells,
            _leaveCellLoopBody,
            0,                     // sharedMemoryGrainSize
            peano::datatraversal::dForLoop<LeaveCellLoopBody>::Serial
          );
        }
        break;
      case peano::MappingSpecification::AvoidCoarseGridRaces:
        {
          const int  sharedMemoryGrainSize   = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(
            tarch::la::volume(NumberOfCells) / SIX_POWER_D,
            peano::datatraversal::autotuning::CallLeaveCellOnRegularStationaryGrid
          );
          peano::datatraversal::dForLoop<LeaveCellLoopBody> loop(
            NumberOfCells,
            _leaveCellLoopBody,
            sharedMemoryGrainSize,
            peano::datatraversal::dForLoop<LeaveCellLoopBody>::SixPowerDColouring
          );
        }
        peano::datatraversal::autotuning::Oracle::getInstance().parallelSectionHasTerminated(peano::datatraversal::autotuning::CallLeaveCellOnRegularStationaryGrid);
        break;
      case peano::MappingSpecification::AvoidFineGridRaces:
        {
          const int  sharedMemoryGrainSize   = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(
            tarch::la::volume(NumberOfCells) / TWO_POWER_D,
            peano::datatraversal::autotuning::CallLeaveCellOnRegularStationaryGrid
          );
          peano::datatraversal::dForLoop<LeaveCellLoopBody> loop(
            NumberOfCells,
            _leaveCellLoopBody,
            sharedMemoryGrainSize,
            peano::datatraversal::dForLoop<LeaveCellLoopBody>::TwoPowerDColouring
          );
          peano::datatraversal::autotuning::Oracle::getInstance().parallelSectionHasTerminated(peano::datatraversal::autotuning::CallLeaveCellOnRegularStationaryGrid);
        }
        break;
      case peano::MappingSpecification::RunConcurrentlyOnFineGrid:
        {
          const int  sharedMemoryGrainSize   = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(
            tarch::la::volume(_gridContainer.getNumberOfCells(level)),
            peano::datatraversal::autotuning::CallLeaveCellOnRegularStationaryGrid
          );
          peano::datatraversal::dForLoop<LeaveCellLoopBody> loop(
            NumberOfCells,
            _leaveCellLoopBody,
            sharedMemoryGrainSize,
            peano::datatraversal::dForLoop<LeaveCellLoopBody>::NoColouring
          );
          peano::datatraversal::autotuning::Oracle::getInstance().parallelSectionHasTerminated(peano::datatraversal::autotuning::CallLeaveCellOnRegularStationaryGrid);
        }
        break;
    }
  }
}


template <class Vertex, class Cell, class State, class EventHandle>
void peano::grid::nodes::tasks::Ascend<Vertex,Cell,State,EventHandle>::ascend(int fineGridLevel) {
  const bool runOperation =
    (_eventHandle.ascendSpecification().manipulates == peano::MappingSpecification::WholeTree) ||
    (_eventHandle.ascendSpecification().manipulates == peano::MappingSpecification::OnlyLeaves && fineGridLevel == _treeDepth);

  if (runOperation) {
    const tarch::la::Vector<DIMENSIONS,int> NumberOfCoarseGridCells = _gridContainer.getNumberOfCells(fineGridLevel-1);

    _ascendLoopBody.setCoarseGridLevel(fineGridLevel-1);

    switch (_eventHandle.ascendSpecification().multithreading) {
      case peano::MappingSpecification::Serial:
        {
          peano::datatraversal::dForLoop<AscendLoopBody> loop(
            NumberOfCoarseGridCells,
            _ascendLoopBody,
            0,
            peano::datatraversal::dForLoop<AscendLoopBody>::Serial
          );
        }
        break;
      case peano::MappingSpecification::AvoidCoarseGridRaces:
        {
          const int sharedMemoryGrainSize   = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(
            tarch::la::volume(NumberOfCoarseGridCells) / TWO_POWER_D,
            peano::datatraversal::autotuning::AscendOnRegularStationaryGrid
          );
          peano::datatraversal::dForLoop<AscendLoopBody> loop(
            NumberOfCoarseGridCells,
            _ascendLoopBody,
            sharedMemoryGrainSize,
            peano::datatraversal::dForLoop<AscendLoopBody>::TwoPowerDColouring
          );
          peano::datatraversal::autotuning::Oracle::getInstance().parallelSectionHasTerminated(peano::datatraversal::autotuning::AscendOnRegularStationaryGrid);
        }
        break;
      case peano::MappingSpecification::AvoidFineGridRaces:
        assertionMsg( false, "ascend configuration " << _eventHandle.leaveCellSpecification().toString() << " not supported" );
        break;
      case peano::MappingSpecification::RunConcurrentlyOnFineGrid:
        {
          const int sharedMemoryGrainSize   = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(
            tarch::la::volume(NumberOfCoarseGridCells),
            peano::datatraversal::autotuning::AscendOnRegularStationaryGrid
          );
          peano::datatraversal::dForLoop<AscendLoopBody> loop(
            NumberOfCoarseGridCells,
            _ascendLoopBody,
            sharedMemoryGrainSize,
            peano::datatraversal::dForLoop<AscendLoopBody>::NoColouring
          );
          peano::datatraversal::autotuning::Oracle::getInstance().parallelSectionHasTerminated(peano::datatraversal::autotuning::AscendOnRegularStationaryGrid);
        }
        break;
    }
  }
}


template <class Vertex, class Cell, class State, class EventHandle>
void peano::grid::nodes::tasks::Ascend<Vertex,Cell,State,EventHandle>::operator() () {
  _treeRemainsStatic = true;

  for (int level=_treeDepth+1; level>=1; level--) {
    if (level==1) {
      ascend(level);
      touchVerticesLastTime( level );
    }
    else if (level==_treeDepth+1) {
      leaveCells(level-1);
    }
    else {
      ascend(level);
      touchVerticesLastTime( level );
      leaveCells(level-1);
    }
  }

  tarch::multicore::BooleanSemaphore performVertexTransitionSemaphore;

  if (_eventHandle.touchVertexLastTimeSpecification().manipulates == peano::MappingSpecification::Nop) {
    const int NumberOfVertices = tarch::la::volume(_gridContainer.getNumberOfVertices(_treeDepth));

    pfor(i,0,NumberOfVertices,peano::datatraversal::autotuning::KernelGrainSizes::ResetVertexRegularityStateInAscendForNopMappings)
      if (!_gridContainer.isToBeWrittenToTemporaryStack(_treeDepth,i) ) {
        Vertex&   currentVertex  = _gridContainer.getVertex(_treeDepth,i);
        tarch::multicore::Lock lock(performVertexTransitionSemaphore);
        _touchVertexLastTimeLoopBody.performVertexTransition(currentVertex,_treeDepth);
      }
    endpfor
  }


  if (
    _eventHandle.touchVertexLastTimeSpecification().manipulates == peano::MappingSpecification::OnlyLeaves
    ||
    _eventHandle.touchVertexLastTimeSpecification().manipulates == peano::MappingSpecification::Nop
  ) {
    pfor(level,1,_treeDepth,peano::datatraversal::autotuning::KernelGrainSizes::RunResetVertexRegularityStateInAscendForNopMappingsInParallelForIndividualLevels)
      const int NumberOfVertices      = tarch::la::volume(_gridContainer.getNumberOfVertices(level));
      pfor(i,0,NumberOfVertices,peano::datatraversal::autotuning::KernelGrainSizes::ResetVertexRegularityStateInAscendForNopMappings)
        if (!_gridContainer.isToBeWrittenToTemporaryStack(level,i) ) {
          Vertex&   currentVertex  = _gridContainer.getVertex(level,i);
          tarch::multicore::Lock lock(performVertexTransitionSemaphore);
          _touchVertexLastTimeLoopBody.performVertexTransition(currentVertex,level);
        }
      endpfor
    endpfor
  }

  // The original loop body is not destroyed yet, i.e. has not merged. Furthermore,
  // if _calledTouchVertexLastTime does not hold, this is the only body that has any
  // static information.
  _treeRemainsStatic &= _touchVertexLastTimeLoopBody.getLocalTreeRemainsStatic();


  if (_treeRemainsStatic) {
    dfor2(i)
      _gridContainer.getVertex(0,iScalar).setCurrentAdjacentCellsHeight(static_cast<peano::grid::CellFlags>(_treeDepth));
    enddforx
  }
  else {
    _state.updateRefinementHistoryBeforeStore(true,true);
    dfor2(i)
      _gridContainer.getVertex(0,iScalar).setCurrentAdjacentCellsHeight(peano::grid::NotStationary);
    enddforx
  }
}
