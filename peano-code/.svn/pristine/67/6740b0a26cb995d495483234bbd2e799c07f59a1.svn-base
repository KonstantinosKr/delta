#include <limits>

#include "tarch/parallel/Node.h"

#ifdef Parallel
#include "peano/parallel/loadbalancing/Oracle.h"
#include "tarch/parallel/NodePool.h"
#include "peano/parallel/SendReceiveBufferPool.h"
#include "peano/parallel/messages/LoadBalancingMessage.h"
#endif


template <class StateData>
tarch::logging::Log  peano::grid::State<StateData>::_log( "peano::grid::State" );


template <class StateData>
const int peano::grid::State<StateData>::IterationsInBetweenRebalancing(3);


template <class StateData>
peano::grid::State<StateData>::State():
  _stateData() {
  _stateData.setIsTraversalInverted(false);

  #ifdef Parallel
  _loadRebalancingState = NoRebalancing;
  _stateData.setReduceStateAndCell(true);
  _loadRebalancingRemoteRanks.clear();
  _iterationCounter = 0;
  _maxForkLevel = std::numeric_limits<int>::max();
  #endif
}

#ifdef PackedRecords
template <class StateData>
peano::grid::State<StateData>::State(const PersistentState& argument):
  _stateData( (typename StateData::Packed(argument)).convert() ) {
}
#else
template <class StateData>
peano::grid::State<StateData>::State(const PersistentState& argument):
  _stateData( argument ) {
}
#endif

template <class StateData>
peano::grid::State<StateData>::~State() {
}



template <class StateData>
void peano::grid::State<StateData>::restart() {
  #ifdef Parallel
  _loadRebalancingState = NoRebalancing;
  #endif
}



template <class StateData>
std::string peano::grid::State<StateData>::toString() const {
  std::ostringstream out;
  toString(out);
  return out.str();
}


template <class StateData>
std::string peano::grid::State<StateData>::toString(LoadBalancingState value) {
  switch (value) {
    case NoRebalancing:
      return "no-rebalancing";
      break;
    case ForkTriggered:
      return "fork-triggered";
      break;
    case Forking:
      return "forking";
      break;
    case JoinTriggered:
      return "join-triggered";
      break;
    case Joining:
      return "joining";
      break;
    case JoinWithMasterTriggered:
      return "join-with-master-triggered";
      break;
    case JoiningWithMaster:
      return "joining-with-master";
      break;
    case HasJoinedWithMaster:
      return "has-joined-with-master";
      break;
    case IsNewWorkerDueToForkOfExistingDomain:
      return "is-new-worker";
      break;
  }

  return "<undef>";
}



template <class StateData>
void peano::grid::State<StateData>::toString(std::ostream& out) const {
  _stateData.toString(out);
  #ifdef Parallel
  out << "[lb-state=" << toString(_loadRebalancingState);
  if (!_loadRebalancingRemoteRanks.empty()) {
    for (std::set<int>::const_iterator p=_loadRebalancingRemoteRanks.begin(); p!=_loadRebalancingRemoteRanks.end(); p++) {
      out << ",";
      out << *p;
    }
  }
  out << ",it=" << _iterationCounter
      << ",level_max=" << _maxForkLevel;
  #ifdef Asserts
  out << ",previous-lb-state=" << toString( _previousLoadRebalancingState );
  #endif
  for (
    std::map<int,bool>::const_iterator p=_stateWillReduce.begin();
    p!=_stateWillReduce.end();
    p++
  ) {
    out << ",reduce-from-" << p->first << "=" << p->second;
  }
  out << "]";
  #endif
}


template <class StateData>
std::ostream& operator<<(std::ostream& out, const peano::grid::State<StateData>& arg) {
  arg.toString(out);
  return out;
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfInnerVertices() const {
  return _stateData.getNumberOfInnerVertices();
}


template <class StateData>
void peano::grid::State<StateData>::changedCellState() {
  _stateData.setHasChangedVertexOrCellState( true );
}


template <class StateData>
bool peano::grid::State<StateData>::isGridStationary() const {
  return !_stateData.getHasChangedVertexOrCellState()
      && !_stateData.getHasRefined()
      && !_stateData.getHasErased()
      && !_stateData.getHasTriggeredRefinementForNextIteration()
      && !_stateData.getHasTriggeredEraseForNextIteration()
  #ifdef Parallel
      && !_stateData.getCouldNotEraseDueToDecompositionFlag();
  #endif
  ;
}


template <class StateData>
bool peano::grid::State<StateData>::isGridBalanced() const {
  #ifdef Parallel
  const bool result =
           !_stateData.getHasChangedVertexOrCellState()
        && !_stateData.getHasRefined()
        && !_stateData.getHasErased()
        && !_stateData.getHasTriggeredRefinementForNextIteration()
        && !_stateData.getHasTriggeredEraseForNextIteration()
        && _iterationCounter > IterationsInBetweenRebalancing+1
        && !isInvolvedInJoinOrFork();

  assertion1(
    !hasSubworkerRebalanced() || !result,
    toString()
  );

  return result;
  #else
  return isGridStationary();
  #endif
}


template <class StateData>
void peano::grid::State<StateData>::updateRefinementHistoryBeforeStore( bool hasTriggeredRefinementForNextIteration, bool hasTriggeredEraseForNextIteration ) {
  _stateData.setHasTriggeredRefinementForNextIteration( _stateData.getHasTriggeredRefinementForNextIteration() || hasTriggeredRefinementForNextIteration );
  _stateData.setHasTriggeredEraseForNextIteration( _stateData.getHasTriggeredEraseForNextIteration() || hasTriggeredEraseForNextIteration );
}


template <class StateData>
void peano::grid::State<StateData>::updateRefinementHistoryAfterLoad(
  bool hasRefinened, bool hasErased, bool hasFailedToEraseDueToDomainDecomposition, bool hasChangedVertexState
) {
  _stateData.setHasRefined( _stateData.getHasRefined() || hasRefinened );
  _stateData.setHasErased( _stateData.getHasErased() || hasErased );
  _stateData.setHasChangedVertexOrCellState( _stateData.getHasChangedVertexOrCellState() || hasChangedVertexState );

  #ifdef Parallel
  _stateData.setCouldNotEraseDueToDecompositionFlag( _stateData.getCouldNotEraseDueToDecompositionFlag() || hasFailedToEraseDueToDomainDecomposition );
  #endif
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfBoundaryVertices() const {
  return _stateData.getNumberOfBoundaryVertices();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfOuterVertices() const {
  return _stateData.getNumberOfOuterVertices();
}


template <class StateData>
int peano::grid::State<StateData>::getMaxLevel() const {
  return _stateData.getMaxLevel();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfInnerCells() const {
  return _stateData.getNumberOfInnerCells();
}


template <class StateData>
bool peano::grid::State<StateData>::isTraversalInverted() const {
  return _stateData.getIsTraversalInverted();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfOuterCells() const {
  return _stateData.getNumberOfOuterCells();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfInnerLeafVertices() const {
  return _stateData.getNumberOfInnerLeafVertices();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfBoundaryLeafVertices() const {
  return _stateData.getNumberOfBoundaryLeafVertices();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfOuterLeafVertices() const {
  return _stateData.getNumberOfOuterLeafVertices();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfInnerLeafCells() const {
  return _stateData.getNumberOfInnerLeafCells();
}


template <class StateData>
double peano::grid::State<StateData>::getNumberOfOuterLeafCells() const {
  return _stateData.getNumberOfOuterLeafCells();
}


template <class StateData>
tarch::la::Vector<DIMENSIONS,double> peano::grid::State<StateData>::getMaximumMeshWidth() const {
  return _stateData.getMaxMeshWidth();
}


template <class StateData>
tarch::la::Vector<DIMENSIONS,double> peano::grid::State<StateData>::getMinimumMeshWidth() const {
  return _stateData.getMinMeshWidth();
}


template <class StateData>
void peano::grid::State<StateData>::resetStateAtEndOfIteration() {
  logTraceInWith1Argument( "resetStateAtEndOfIteration()", toString() );

  _stateData.setIsTraversalInverted(!_stateData.getIsTraversalInverted());

  if (tarch::parallel::Node::getInstance().isGlobalMaster()) {
    _stateData.setHasModifiedGridInPreviousIteration(
      _stateData.getHasChangedVertexOrCellState() |
      _stateData.getHasErased() |
      _stateData.getHasRefined() |
      _stateData.getHasTriggeredEraseForNextIteration() |
      _stateData.getHasTriggeredRefinementForNextIteration()
    );
  }

  #ifdef Parallel

  #ifdef Asserts
  _previousLoadRebalancingState = _loadRebalancingState;
  #endif

  _stateWillReduce.clear();

  if (
    _loadRebalancingState == NoRebalancing &&
    peano::parallel::loadbalancing::Oracle::getInstance().getLastStartCommand()>=peano::parallel::loadbalancing::ForkOnce &&
    _maxForkLevel < std::numeric_limits<int>::max()
  ) {
    _maxForkLevel++;
  }

  switch (_loadRebalancingState) {
    case NoRebalancing:
      assertion( _loadRebalancingRemoteRanks.empty());
      _stateData.setHasChangedVertexOrCellState(false);
      _iterationCounter++;
      break;
    case ForkTriggered:
      assertion( !_loadRebalancingRemoteRanks.empty());
      assertion2(!isGridStationary(),toString(),tarch::parallel::Node::getInstance().getRank());
      _loadRebalancingState = Forking;
      _stateData.setHasChangedVertexOrCellState(true);
      _iterationCounter=0;
      break;
    case Forking:
      assertion( !_loadRebalancingRemoteRanks.empty());
      _loadRebalancingState = NoRebalancing;
      _stateData.setHasChangedVertexOrCellState(true);
      _loadRebalancingRemoteRanks.clear();
      break;
    case JoinTriggered:
      assertion( !_loadRebalancingRemoteRanks.empty());
      assertion2(!isGridStationary(),toString(),tarch::parallel::Node::getInstance().getRank());
      _loadRebalancingState = Joining;
      _stateData.setHasChangedVertexOrCellState(true);
      _iterationCounter=0;
      break;
    case Joining:
      assertion( !_loadRebalancingRemoteRanks.empty());
      assertion2(!isGridStationary(),toString(),tarch::parallel::Node::getInstance().getRank());
      _loadRebalancingState = NoRebalancing;
      _stateData.setHasChangedVertexOrCellState(true);
      _loadRebalancingRemoteRanks.clear();
      break;
    case IsNewWorkerDueToForkOfExistingDomain:
      assertion2(!isGridStationary(),toString(),tarch::parallel::Node::getInstance().getRank());
      _stateData.setHasChangedVertexOrCellState(true);
      _loadRebalancingState = NoRebalancing;
      _iterationCounter=0;
      break;
    case JoinWithMasterTriggered:
      assertion(_loadRebalancingRemoteRanks.empty());
      _stateData.setHasChangedVertexOrCellState(true);
      _loadRebalancingState = JoiningWithMaster;
      _iterationCounter=0;
      break;
    case JoiningWithMaster:
      assertion(_loadRebalancingRemoteRanks.empty());
      assertion2(!isGridStationary(), toString(),tarch::parallel::Node::getInstance().getRank() );
      _stateData.setHasChangedVertexOrCellState(true);
      _loadRebalancingState = HasJoinedWithMaster;
      break;
    default:
      assertion3( false, "unknown rebalancing state", _stateData.toString(), tarch::parallel::Node::getInstance().getRank() );
      break;
  }
  #endif

  logTraceOutWith1Argument( "resetStateAtEndOfIteration()", toString() );
}


template <class StateData>
bool peano::grid::State<StateData>::hasGridChangedInPreviousIteration() const {
  return _stateData.getHasModifiedGridInPreviousIteration();
}


template <class StateData>
void peano::grid::State<StateData>::resetStateAtBeginOfIteration() {
  logTraceInWith1Argument( "resetStateAtBeginOfIteration()", toString() );

  _stateData.setHasChangedVertexOrCellState(false);
  _stateData.setHasErased(false);
  _stateData.setHasRefined(false);
  _stateData.setHasTriggeredEraseForNextIteration(false);
  _stateData.setHasTriggeredRefinementForNextIteration(false);

  _stateData.setMaxLevel(0);
  _stateData.setMaxMeshWidth(tarch::la::Vector<DIMENSIONS,double>(0.0));
  _stateData.setMinMeshWidth(tarch::la::Vector<DIMENSIONS,double>(std::numeric_limits<double>::max()));

  _stateData.setNumberOfInnerVertices(0.0);
  _stateData.setNumberOfBoundaryVertices(0.0);
  _stateData.setNumberOfOuterVertices(0.0);
  _stateData.setNumberOfInnerCells(0.0);
  _stateData.setNumberOfOuterCells(0.0);

  _stateData.setNumberOfInnerLeafVertices(0.0);
  _stateData.setNumberOfBoundaryLeafVertices(0.0);
  _stateData.setNumberOfOuterLeafVertices(0.0);
  _stateData.setNumberOfInnerLeafCells(0.0);
  _stateData.setNumberOfOuterLeafCells(0.0);

  #ifdef Parallel
  _stateData.setCouldNotEraseDueToDecompositionFlag(false);
  _stateData.setSubWorkerIsInvolvedInJoinOrFork( _loadRebalancingState != NoRebalancing );
  #endif

  logTraceOutWith1Argument( "resetStateAtBeginOfIteration()", toString() );
}


template <class StateData>
void peano::grid::State<StateData>::updateInLeaf( int level, const tarch::la::Vector<DIMENSIONS,double>& h ) {
  _stateData.setMaxLevel(
    _stateData.getMaxLevel()>level ? _stateData.getMaxLevel() : level
  );
  for (int d=0; d<DIMENSIONS; d++) {
    _stateData.setMaxMeshWidth(d,
      _stateData.getMaxMeshWidth(d)<h(d) ? h(d) : _stateData.getMaxMeshWidth(d)
	  );
    _stateData.setMinMeshWidth(d,
      _stateData.getMinMeshWidth(d)>h(d) ? h(d) : _stateData.getMinMeshWidth(d)
	  );
  }
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfInnerVertices( double increment ) {
  _stateData.setNumberOfInnerVertices(_stateData.getNumberOfInnerVertices()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfBoundaryVertices( double increment ) {
  _stateData.setNumberOfBoundaryVertices(_stateData.getNumberOfBoundaryVertices()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfOuterVertices( double increment ) {
  _stateData.setNumberOfOuterVertices(_stateData.getNumberOfOuterVertices()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfInnerCells( double increment ) {
  _stateData.setNumberOfInnerCells(_stateData.getNumberOfInnerCells()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfOuterCells( double increment ) {
  _stateData.setNumberOfOuterCells(_stateData.getNumberOfOuterCells()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfInnerLeafVertices( double increment ) {
  _stateData.setNumberOfInnerVertices(_stateData.getNumberOfInnerVertices()+increment);
  _stateData.setNumberOfInnerLeafVertices(_stateData.getNumberOfInnerLeafVertices()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfBoundaryLeafVertices( double increment ) {
  _stateData.setNumberOfBoundaryVertices(_stateData.getNumberOfBoundaryVertices()+increment);
  _stateData.setNumberOfBoundaryLeafVertices(_stateData.getNumberOfBoundaryLeafVertices()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfOuterLeafVertices( double increment ) {
  _stateData.setNumberOfOuterVertices(_stateData.getNumberOfOuterVertices()+increment);
  _stateData.setNumberOfOuterLeafVertices(_stateData.getNumberOfOuterLeafVertices()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfInnerLeafCells( double increment ) {
  _stateData.setNumberOfInnerCells(_stateData.getNumberOfInnerCells()+increment);
  _stateData.setNumberOfInnerLeafCells(_stateData.getNumberOfInnerLeafCells()+increment);
}


template <class StateData>
void peano::grid::State<StateData>::incNumberOfOuterLeafCells( double increment ) {
  _stateData.setNumberOfOuterCells(_stateData.getNumberOfOuterCells()+increment);
  _stateData.setNumberOfOuterLeafCells(_stateData.getNumberOfOuterLeafCells()+increment);
}

#ifdef Parallel
template <class StateData>
std::set<int> peano::grid::State<StateData>::getForkingOrJoiningOrTriggeredForRebalancingRanks() const {
  return _loadRebalancingRemoteRanks;
}


template <class StateData>
void peano::grid::State<StateData>::mergeWithWorkerState(const peano::grid::State<StateData>& workerState) {
  logTraceInWith2Arguments( "mergeWithWorkerState(...)", toString(), workerState.toString() );

  _stateData.setNumberOfInnerVertices( _stateData.getNumberOfInnerVertices() + workerState._stateData.getNumberOfInnerVertices());
  _stateData.setNumberOfBoundaryVertices( _stateData.getNumberOfBoundaryVertices() + workerState._stateData.getNumberOfBoundaryVertices());
  _stateData.setNumberOfOuterVertices( _stateData.getNumberOfOuterVertices() + workerState._stateData.getNumberOfOuterVertices());
  _stateData.setNumberOfInnerCells( _stateData.getNumberOfInnerCells() + workerState._stateData.getNumberOfInnerCells());
  _stateData.setNumberOfOuterCells( _stateData.getNumberOfOuterCells() + workerState._stateData.getNumberOfOuterCells());

  _stateData.setNumberOfInnerLeafVertices( _stateData.getNumberOfInnerLeafVertices() + workerState._stateData.getNumberOfInnerLeafVertices() );
  _stateData.setNumberOfBoundaryLeafVertices( _stateData.getNumberOfBoundaryLeafVertices() + workerState._stateData.getNumberOfBoundaryLeafVertices());
  _stateData.setNumberOfOuterLeafVertices( _stateData.getNumberOfOuterLeafVertices() + workerState._stateData.getNumberOfOuterLeafVertices());
  _stateData.setNumberOfInnerLeafCells( _stateData.getNumberOfInnerLeafCells() + workerState._stateData.getNumberOfInnerLeafCells());
  _stateData.setNumberOfOuterLeafCells( _stateData.getNumberOfOuterLeafCells() + workerState._stateData.getNumberOfOuterLeafCells());

  _stateData.setHasChangedVertexOrCellState(workerState._stateData.getHasChangedVertexOrCellState() || _stateData.getHasChangedVertexOrCellState());

  _stateData.setHasChangedVertexOrCellState(            _stateData.getHasChangedVertexOrCellState()            | workerState._stateData.getHasChangedVertexOrCellState() );
  _stateData.setHasRefined(                             _stateData.getHasRefined()                             | workerState._stateData.getHasRefined() );
  _stateData.setHasErased(                              _stateData.getHasErased()                              | workerState._stateData.getHasErased() );
  _stateData.setHasTriggeredRefinementForNextIteration( _stateData.getHasTriggeredRefinementForNextIteration() | workerState._stateData.getHasTriggeredRefinementForNextIteration() );
  _stateData.setHasTriggeredEraseForNextIteration(      _stateData.getHasTriggeredEraseForNextIteration()      | workerState._stateData.getHasTriggeredEraseForNextIteration() );

  _stateData.setMaxLevel( workerState._stateData.getMaxLevel() > _stateData.getMaxLevel() ? workerState._stateData.getMaxLevel() : _stateData.getMaxLevel() );
  for (int d=0; d<DIMENSIONS; d++) {
    _stateData.setMaxMeshWidth(d,
      workerState._stateData.getMaxMeshWidth(d) > _stateData.getMaxMeshWidth(d) ? workerState._stateData.getMaxMeshWidth(d) : _stateData.getMaxMeshWidth(d)
    );
    _stateData.setMinMeshWidth(d,
      workerState._stateData.getMinMeshWidth(d) < _stateData.getMinMeshWidth(d) ? workerState._stateData.getMinMeshWidth(d) : _stateData.getMinMeshWidth(d)
    );
  }

  _stateData.setCouldNotEraseDueToDecompositionFlag(
    _stateData.getCouldNotEraseDueToDecompositionFlag() |
    workerState._stateData.getCouldNotEraseDueToDecompositionFlag()
  );

  _stateData.setSubWorkerIsInvolvedInJoinOrFork(
    _stateData.getSubWorkerIsInvolvedInJoinOrFork() ||
    workerState._stateData.getSubWorkerIsInvolvedInJoinOrFork()
  );

  if (workerState._stateData.getSubWorkerIsInvolvedInJoinOrFork()) {
    _iterationCounter = 0;
  }

  logTraceOutWith1Argument( "mergeWithWorkerState(...)", toString() );
}


template <class StateData>
void peano::grid::State<StateData>::initDatatype() {
  if (StateData::Packed::Datatype==0) {
    StateData::Packed::initDatatype();
  }
  if (StateData::Datatype==0) {
    StateData::initDatatype();
  }

  assertion(StateData::Packed::Datatype!=0);
  assertion(StateData::Datatype!=0);
}


template <class StateData>
void peano::grid::State<StateData>::shutdownDatatype() {
  if (StateData::Packed::Datatype!=0) {
    StateData::Packed::shutdownDatatype();
  }
  if (StateData::Datatype!=0) {
    StateData::shutdownDatatype();
  }

  StateData::Datatype = 0;
  StateData::Packed::Datatype = 0;
}


template <class StateData>
void peano::grid::State<StateData>::send(int destination, int tag, bool exchangeDataBlocking) {
  assertion(MPIDatatypeContainer::Datatype!=0);

  #if defined(ParallelExchangePackedRecordsBetweenMasterAndWorker)
  _stateData.convert().send(destination,tag,true,exchangeDataBlocking);
  #else
  _stateData.send(destination,tag,true,exchangeDataBlocking);
  #endif
}


template <class StateData>
void peano::grid::State<StateData>::receive(int source, int tag, bool exchangeDataBlocking) {
  assertion(MPIDatatypeContainer::Datatype!=0);

  #if defined(ParallelExchangePackedRecordsBetweenMasterAndWorker)
  MPIDatatypeContainer receivedMessage;
  receivedMessage.receive(source,tag,true,exchangeDataBlocking);
  _stateData = receivedMessage.convert();
  #else
  _stateData.receive(source,tag,true,exchangeDataBlocking);
  #endif
}


template <class StateData>
void peano::grid::State<StateData>::joinWithRank( int rank ) {
  assertion( rank!=tarch::parallel::Node::getInstance().getRank() );

  if (rank==tarch::parallel::NodePool::getInstance().getMasterRank()) {
    assertion(  _loadRebalancingState==NoRebalancing );
    assertion( _loadRebalancingRemoteRanks.empty() );
    _loadRebalancingState = JoinWithMasterTriggered;
  }
  else {
    assertion(
      (_loadRebalancingState == NoRebalancing) ||
      (_loadRebalancingState == JoinTriggered)
    );
    _loadRebalancingState = JoinTriggered;
    _loadRebalancingRemoteRanks.insert(rank);
  }

  changedCellState();
}


template <class StateData>
void peano::grid::State<StateData>::splitIntoRank( int rank ) {
  assertion(
    (_loadRebalancingState==NoRebalancing) ||
    (_loadRebalancingState==ForkTriggered)
  );
  assertion( rank!=tarch::parallel::Node::getInstance().getRank() );
  assertion( _loadRebalancingRemoteRanks.count(rank)==0 );

  _loadRebalancingState = ForkTriggered;
  _loadRebalancingRemoteRanks.insert(rank);

  changedCellState();
}


template <class StateData>
bool peano::grid::State<StateData>::isForking() const {
  return _loadRebalancingState == Forking;
}


template <class StateData>
bool peano::grid::State<StateData>::isInvolvedInJoinOrFork() const {
  return _loadRebalancingState != NoRebalancing;
}


template <class StateData>
bool peano::grid::State<StateData>::mayUseLazyStateAndDataReceives() const {
  return (_loadRebalancingState == NoRebalancing) && _currentlyRunsMultipleIterations;
}


template <class StateData>
void peano::grid::State<StateData>::currentlyRunsMultipleIterations(bool value) {
  _currentlyRunsMultipleIterations = value;
}


template <class StateData>
bool peano::grid::State<StateData>::isForkTriggeredForRank(int rank) const {
  assertion( rank!=tarch::parallel::Node::getInstance().getRank() || _loadRebalancingRemoteRanks.count(rank)==0 );
  return (_loadRebalancingState == ForkTriggered) && (_loadRebalancingRemoteRanks.count(rank)>0);
}


template <class StateData>
bool peano::grid::State<StateData>::isJoinTriggered() const {
  return (_loadRebalancingState == JoinTriggered) || (_loadRebalancingState == JoinWithMasterTriggered);
}


template <class StateData>
bool peano::grid::State<StateData>::isJoinTriggeredForRank(int rank) const {
  assertion( rank!=tarch::parallel::Node::getInstance().getRank() || _loadRebalancingRemoteRanks.count(rank)==0 );
  return (_loadRebalancingState == JoinTriggered) && (_loadRebalancingRemoteRanks.count(rank)>0);
}


template <class StateData>
bool peano::grid::State<StateData>::isForkTriggered() const {
  return _loadRebalancingState == ForkTriggered;
}


template <class StateData>
bool peano::grid::State<StateData>::isForkingRank( int rank ) const {
    assertion( rank!=tarch::parallel::Node::getInstance().getRank() || _loadRebalancingRemoteRanks.count(rank)==0 );
  return _loadRebalancingState == Forking && _loadRebalancingRemoteRanks.count(rank)>0;
}


template <class StateData>
bool peano::grid::State<StateData>::isJoiningRank(int rank) const {
  return (_loadRebalancingState == Joining && _loadRebalancingRemoteRanks.count(rank) > 0);
}


template <class StateData>
bool peano::grid::State<StateData>::isNewWorkerDueToForkOfExistingDomain() const {
  return _loadRebalancingState == IsNewWorkerDueToForkOfExistingDomain;
}


template <class StateData>
void peano::grid::State<StateData>::setIsNewWorkerDueToForkOfExistingDomain(bool value) {
  if (value) {
    _loadRebalancingState = IsNewWorkerDueToForkOfExistingDomain;
  }
  else {
    _loadRebalancingState = NoRebalancing;
  }
}


template <class StateData>
bool peano::grid::State<StateData>::getCouldNotEraseDueToDecompositionFlag() const {
  return _stateData.getCouldNotEraseDueToDecompositionFlag();
}


template <class StateData>
bool peano::grid::State<StateData>::isJoinWithMasterTriggered() const {
  return _loadRebalancingState == JoinWithMasterTriggered;
}


template <class StateData>
bool peano::grid::State<StateData>::isJoiningWithMaster() const {
  return _loadRebalancingState == JoiningWithMaster;
}


template <class StateData>
bool peano::grid::State<StateData>::isJoiningWithWorker() const {
  return _loadRebalancingState == Joining;
}


template <class StateData>
bool peano::grid::State<StateData>::hasJoinedWithMaster() const {
  bool result = _loadRebalancingState == HasJoinedWithMaster;
  return result;
}


template <class StateData>
void peano::grid::State<StateData>::setReduceStateAndCell( bool value ) {
  _stateData.setReduceStateAndCell(value);
}


template <class StateData>
void peano::grid::State<StateData>::setReduceStateAndCell( int worker, bool value ) {
  _stateWillReduce[worker] = value;
}


template <class StateData>
bool peano::grid::State<StateData>::reduceDataToMaster() const {
  return _stateData.getReduceStateAndCell() &&
         _loadRebalancingState != JoiningWithMaster &&
         _loadRebalancingState != IsNewWorkerDueToForkOfExistingDomain &&
         !tarch::parallel::Node::getInstance().isGlobalMaster();
}


template <class StateData>
bool peano::grid::State<StateData>::reduceDataFromWorker( int rank ) const {
  assertion1(
    _stateWillReduce.count(rank)==1
    ||
    _previousLoadRebalancingState==Forking,
    toString()
  );

  if ( _stateWillReduce.count(rank)==0) {
    return true;
  }
  else {
    return _stateWillReduce.at(rank);
  }
}



template <class StateData>
bool peano::grid::State<StateData>::mayForkCellsOnLevel(int level) {
  const bool result = level <= _maxForkLevel;
  if (level<_maxForkLevel) {
    _maxForkLevel = level;
  }
  return result;
}


template <class StateData>
bool peano::grid::State<StateData>::mayForkDueToLoadBalancing() const {
  if (_iterationCounter<IterationsInBetweenRebalancing) return false;

  return _loadRebalancingState == NoRebalancing ||
         _loadRebalancingState == ForkTriggered;
}


template <class StateData>
bool peano::grid::State<StateData>::mayJoinDueToLoadBalancing() const {
  if (_iterationCounter<IterationsInBetweenRebalancing) return false;

  return _loadRebalancingState == NoRebalancing;
}


template <class StateData>
bool peano::grid::State<StateData>::hasSubworkerRebalanced() const {
  return _stateData.getSubWorkerIsInvolvedInJoinOrFork();
}



template <class StateData>
void peano::grid::State<StateData>::receiveStartupDataFromMaster() {
  logTraceInWith1Argument( "receiveStartupDataFromMaster()", toString() );
  if ( tarch::parallel::Node::getInstance().isGlobalMaster()) {
    setReduceStateAndCell(true);
  }
  else if ( !isJoiningWithMaster() ) {
    peano::parallel::messages::LoadBalancingMessage loadBalancingMessage;
    loadBalancingMessage.receive(
      tarch::parallel::NodePool::getInstance().getMasterRank(),
      peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag(),
      true,
      ReceiveMasterMessagesBlocking
    );

    assertion(
      loadBalancingMessage.getLoadBalancingFlag()!=peano::parallel::loadbalancing::Join ||
      !peano::parallel::loadbalancing::Oracle::getInstance().hasWorkers()
    );

    if ( isInvolvedInJoinOrFork() ) {
      peano::parallel::loadbalancing::Oracle::getInstance().receivedStartCommand(
        peano::parallel::loadbalancing::Continue
      );
    }
    else {
      peano::parallel::loadbalancing::Oracle::getInstance().receivedStartCommand(loadBalancingMessage.getLoadBalancingFlag());
    }

    if (peano::parallel::loadbalancing::Oracle::getInstance().getLastStartCommand()==peano::parallel::loadbalancing::Join) {
      joinWithRank(tarch::parallel::NodePool::getInstance().getMasterRank());
    }

    receive(
      tarch::parallel::NodePool::getInstance().getMasterRank(),
      peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag(),
      ReceiveMasterMessagesBlocking
    );

    logDebug( "receiveStartupDataFromMaster()", "received state " << toString() );
  }

  logTraceOutWith1Argument( "receiveStartupDataFromMaster()", toString() );
}


template <class StateData>
void peano::grid::State<StateData>::sendStateToMaster() const {
  logTraceInWith1Argument( "sendStateToMaster()", toString() );

  if ( reduceDataToMaster() ) {
    // stupid workaround as send is non-const
    State stateCopy(*this);
    stateCopy.send(
      tarch::parallel::NodePool::getInstance().getMasterRank(),
      peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag(),
      SendWorkerMasterMessagesBlocking
    );
    logDebug( "sendStateToMaster()", "sent state " << stateCopy.toString() );
  }

  logTraceOut( "sendStateToMaster()" );
}

#endif

