@MISC{Software:Delta,
  author = {K. Krestenitis and T. Koziara and T. Weinzierl},
  title = {Delta},
  year = {2016},
  note = {github.com/KonstantinosKr/delta},
  url = {https://github.com/KonstantinosKr/delta}
}


@MISC{Software:Peano,
  author = {T. Weinzierl and others},
  title = {Peano---a {F}ramework for {PDE} {S}olvers on {S}pacetree {G}rids},
  year = {2016},
  note = {www.peano-framework.org},
  url = {http://www.peano-framework.org}
}


@inproceedings{Treibig:10:Likwid,
 author    = {Treibig, J. and Hager, G. and Wellein, G.},
 title     = {{LIKWID}: {A} {L}ightweight {P}erformance-{O}riented {T}ool {S}uite for x86 {M}ulticore {E}nvironments},
 booktitle = {Proceedings of the 2010 39th International Conference on Parallel Processing Workshops},
 series    = {ICPPW '10},
 year      = {2010},
 pages     = {207--216},
 publisher = {IEEE Computer Society}
} 


@BOOK{Weinzierl:2009:Diss,
  title = {A {F}ramework for {P}arallel {PDE} {S}olvers on {M}ultiscale {A}daptive
    {C}artesian {G}rids},
  publisher = {Verlag Dr. Hut},
  year = {2009},
  author = {Weinzierl, T.},
  address = {M{\"{u}}nchen},
  isbn = {9783868531461},
  type = {Dissertation},
  url = {http://www.dr.hut-verlag.de/978-3-86853-146-6.html}
}

@ARTICLE{Weinzierl:11:Peano,
  author = {Weinzierl, T. and Mehl, M.},
  title = {{Peano -- A Traversal and Storage Scheme for Octree-Like Adaptive
    Cartesian Multiscale Grids}},
  journal = {SIAM Journal on Scientific Computing},
  year = {2011},
  volume = {33},
  pages = {2732--2760},
  number = {5},
  month = oct,
  editor = {Tuminaro, R. and Benzi, M. and Cai, X.-C. and Duff, I. and Elman,
    H. and Freund, R. and Jordan, K. and Kelley, T. and Keyes, D. and
    Kilmer, M. and Leyffer, S. and Manteuffel, T. and McCormick, S. and
    Silvester, D. and Walker, H. and Woodward, C. and Yavneh, I.},
  institution = {SIAM},
  issn = {1064-8275},
  organization = {SIAM},
  series = {Special Section: 2010 Copper Mountain Conference},
  url = {http://link.aip.org/link/?SCE/33/2732}
}


%  editor      = {},
%  OPTvolume =   {},
%  OPTnumber =   {},
@InProceedings{Weinzierl:15:Compression,
  author      = {Eckhardt, W. and Glas, R. and Korzh, D. and Wallner, S. and Weinzierl, T.},  
  title       = {On-the-fly memory compression for multibody algorithms},
  year        = {2015},
  booktitle   = {Advances in Parallel Computing},
  publisher = {IOS Press},
  note = 	 {(in press)},
  annote = 	 {(in press)}
}


@Article{Weinzierl:16:PIC,
  author   = {Weinzierl, T. and Verleye, B. and Henri, P. and Roose, D.},
  title    = {Two Particle-in-Grid Realisations on Spacetrees},
  journal  = {Parallel Computing},
  year = 	 {2016},
  volume = 	 {52},
  pages = 	 {42--64}
}

%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/
%% Created for Konstantinos at 2016-03-03 17:49:35 +0000 
%% Saved with string encoding Unicode (UTF-8) 

@techreport{Forum:1994:MMI:898758,
 author = {Forum, Message P},
 title = {MPI: A Message-Passing Interface Standard},
 year = {1994},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autk_cs%3Ancstrl.utk_cs%2F%2FUT-CS-94-230},
 publisher = {University of Tennessee},
 address = {Knoxville, TN, USA},
}

@article{Dagum:1998:OIA:615255.615542,
 author = {Dagum, Leonardo and Menon, Ramesh},
 title = {OpenMP: An Industry-Standard API for Shared-Memory Programming},
 journal = {IEEE Comput. Sci. Eng.},
 issue_date = {January 1998},
 volume = {5},
 number = {1},
 month = jan,
 year = {1998},
 issn = {1070-9924},
 pages = {46--55},
 numpages = {10},
 url = {http://dx.doi.org/10.1109/99.660313},
 doi = {10.1109/99.660313},
 acmid = {615542},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
}


@Article{ZoltanIsorropiaOverview2012,
   author = {E. G. Boman and U. V. Catalyurek and C. Chevalier and K. D. Devine}, 
   title = {The {Z}oltan and {I}sorropia Parallel Toolkits for Combinatorial Scientific Computing: Partitioning, Ordering, and Coloring}, 
   journal = {Scientific Programming}, 
   year = {2012}, 
   volume = {20}, 
   number = {2}, 
   pages = {129--150} 
} 

@inproceedings{psti,
author = {Treibig, J. and Hager, G. and Wellein, G.},
booktitle = {Proceedings of PSTI2010, the First International Workshop on Parallel Software Tools and Tool Infrastructures},
title = {LIKWID: A lightweight performance-oriented tool suite for x86 multicore environments},
year = {2010},
address = {San Diego CA},
}


@article{Williams1999,
	Abstract = {This paper addresses the problem of contact detection in discrete element multibody dynamic simulations. We present an overview of the problem and a detail description of a new object representation scheme called the discrete function representation (DFR). This representation is designed to reduce the computational cost of both contact detection and the more difficult problem of contact resolution. The scheme has a maximum theoretical complexity of order O(N) for contact resolution between bodies defined by N boundary points. In practice, the discrete element method constrains overlap between objects and the actual complexity is approximately O((N) giving a speedup of nearly 2 orders of magnitude over traditional algorithms for systems withmore than 1000 objects. The technique is robust and is able to handle convexand concave object geometries, including objects containing holes. Examples of relatively large discrete element simulations in three dimensions are presented.},
	Author = {Williams, J R and Connor, R O},
	Doi = {10.1007/BF02818917},
	File = {:Users/konstantinos/Google Drive/papers/Discrete Element Simulation and the Contact Problem{\_}Williams, Connor.pdf:pdf},
	Isbn = {1134-3060},
	Issn = {1134-3060},
	Journal = {Methods in Engineering},
	Number = {June 1996},
	Pages = {279--304},
	Title = {{Discrete Element Simulation and the Contact Problem}},
	Volume = {6},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BF02818917}}

@article{Omelyan1998,
	Abstract = {An algorithm for numerical integration of the rigid-body equations of motion is proposed. The algorithm uses the leapfrog scheme and the quantities involved are angular velocities and orientational variables that can be expressed in terms of either principal axes or quaternions. Due to specific features of the algorithm, orthonormality and unit norms of the orientational variables are integrals of motion, despite an approximate character of the produced trajectories. It is shown that the method presented appears to be the most efficient among all such algorithms known.},
	Archiveprefix = {arXiv},
	Arxivid = {physics/9901027},
	Author = {Omelyan, Igor P.},
	Doi = {10.1103/PhysRevE.58.1169},
	Eprint = {9901027},
	File = {:Users/konstantinos/Google Drive/papers/Algorithm for numerical integration of the rigid-body equations of motion{\_}Omelyan.pdf:pdf},
	Issn = {1063-651X},
	Journal = {Physical Review E},
	Number = {1},
	Pages = {1169--1172},
	Primaryclass = {physics},
	Title = {{Algorithm for numerical integration of the rigid-body equations of motion}},
	Url = {http://link.aps.org/doi/10.1103/PhysRevE.58.1169$\backslash$nhttp://pre.aps.org/abstract/PRE/v58/i1/p1169{\_}1$\backslash$nhttp://pre.aps.org/pdf/PRE/v58/i1/p1169{\_}1},
	Volume = {58},
	Year = {1998},
	Bdsk-Url-1 = {http://link.aps.org/doi/10.1103/PhysRevE.58.1169$%5Cbackslash$nhttp://pre.aps.org/abstract/PRE/v58/i1/p1169%7B%5C_%7D1$%5Cbackslash$nhttp://pre.aps.org/pdf/PRE/v58/i1/p1169%7B%5C_%7D1},
	Bdsk-Url-2 = {http://dx.doi.org/10.1103/PhysRevE.58.1169}}

@article{Karajan2014,
	Abstract = {The goal of this contribution is to discuss the assumptions made when modeling granular media with the discrete-element method (DEM). Here in, particular focus is drawn on the physical interpretation of the involved material parameters of the DEM in LS-DYNA {\textregistered} . Following this, the influence of each parameter on the bulk behavior of granular media is investigated and different possibilities to estimate these parameters are presented.},
	Author = {Karajan, Nils and Han, Zhidong and Teng, Hailong and Wang, Jason},
	File = {:Users/konstantinos/Google Drive/papers/On the Parameter Estimation for the Discrete-Element Method in LS-DYNA {\textregistered}{\_}Karajan et al.pdf:pdf},
	Journal = {13 th International LS-DYNA Users Conference},
	Pages = {1--9},
	Title = {{On the Parameter Estimation for the Discrete-Element Method in LS-DYNA {\textregistered}}},
	Year = {2014}}

@article{Koziara2005,
	Author = {Koziara, Tomasz and Detection, Collision and Approach, Sweep-plane and Hashing, Spatial and Tree, Priority Search},
	File = {:Users/konstantinos/Google Drive/papers/Sweep-plane approach to bounding box{\_}Koziara et al.pdf:pdf},
	Isbn = {8495999781},
	Journal = {Complas VIII},
	Keywords = {aligned bounding box intersection,an optimal sweep-,bounding box intersection,collision detection,effort towards approximation of,in particular a spatial,plane approach to axis,priority search tree,problem,spatial hashing,summary,sweep-plane approach,this paper summarises an},
	Pages = {1--4},
	Title = {{Sweep-plane approach to bounding box}},
	Year = {2005}}

@article{Wachs2012a,
	Author = {Wachs, Anthony and Rakotonirina, Andriarimina Daniel},
	File = {:Users/konstantinos/Google Drive/papers/A MPI domain decomposition strategy for large-scale simulations of granular media made of particles of arbitrary shape{\_}Wachs, Rakotonir.pdf:pdf},
	Number = {2011},
	Pages = {69360},
	Title = {{A MPI / domain decomposition strategy for large-scale simulations of granular media made of particles of arbitrary shape}},
	Volume = {130},
	Year = {2012}}

@article{Parteli2013,
	Abstract = {Additive manufacturing constitutes a promising production technology with potential application in a broad range of industrial areas. In this type of manufacturing process, objects are created from powder particles by adding layers of material upon one another through selectively melting particles from the powder bed. However, understanding the mechanical behavior of the powder during manufacturing as a function of material properties and particle shape is an essential pre-requisite for optimizing the production process. Here we develop a numerical tool for modeling the dynamics of powder particles during additive manufacturing based on force-based simulations by means of the Discrete Element Method (DEM). An existing DEM software (LIGGGHTS) is extended in order to study the transport of powder particles of complex geometric shapes through accounting for the boundary conditions inherent to the manufacturing process. {\copyright} 2013 AIP Publishing LLC.},
	Author = {Parteli, Eric J R},
	Doi = {10.1063/1.4811898},
	File = {:Users/konstantinos/Google Drive/papers/DEM simulation of particles of complex shapes using the multisphere method Application for additive manufacturing{\_}Parteli.pdf:pdf},
	Isbn = {9780735411661},
	Issn = {0094243X},
	Journal = {AIP Conference Proceedings},
	Keywords = {DEM simulation,additive manufacturing,granular materials,multisphere method},
	Pages = {185--188},
	Title = {{DEM simulation of particles of complex shapes using the multisphere method: Application for additive manufacturing}},
	Volume = {1542},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1063/1.4811898}}

@article{Girolami2012,
	Abstract = {In this paper, we used a 3-D discrete-element model, Grains3D, which allows the simulation of unsteady granular flows of monodisperse soft spherical particles in a common situation (i.e., down a rectangular channel). A series of numerical dam-break experiments was performed to predict the behavior of granular columns that propagate down a rough horizontal surface from different initial conditions (varying the initial aspect ratio). Numerical results were compared to those obtained experimentally by Lajeunesse et al. (Phys Fluids 17:103302, 2005 ) from a similar configuration. Runout distance, temporal flow evolution, deposit morphology and internal flow structures of similar laboratory experiments were quantitatively reproduced as well as prediction of empirical and theoretical scaling laws. This paper highlights that such fully 3-D simulations of soft-spheres can remarkably capture dam-break collapses performed in a rectangular channel. Moreover, Grains3D can provide a complete physical description of such complex unsteady systems which will be the topic of future on-going studies.},
	Author = {Girolami, L. and Hergault, V. and Vinay, G. and Wachs, A.},
	Doi = {10.1007/s10035-012-0342-3},
	File = {:Users/konstantinos/Google Drive/papers/A three-dimensional discrete-grain model for the simulation of dam-break rectangular collapses Comparison between numerical results and.pdf:pdf},
	Isbn = {1434-5021},
	Issn = {14345021},
	Journal = {Granular Matter},
	Keywords = {Dam-break flows,Discrete-element modeling,Quantitative reproductio},
	Number = {3},
	Pages = {381--392},
	Title = {{A three-dimensional discrete-grain model for the simulation of dam-break rectangular collapses: Comparison between numerical results and experiments}},
	Volume = {14},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10035-012-0342-3}}

@article{Iglberger2010,
	Abstract = {Although granular materials have always been an important part of our everyday life, their characteristics and behavior is still only rudimentally understood. Therefore the numerical simulation has gained an increasing importance to gain deeper insight into the properties of granular media. One simulation approach is rigid body dynamics. In contrast to particle-based approaches, it fully resolves the granular particles as geometric objects and incorporates frictional contact dynamics. However, due to its complexity and the lack of large-scale parallelization, rigid body dynamics so far could not be used for very large simulation scenarios.   In this paper we demonstrate massively parallel granular media simulations by means of a parallel rigid body dynamics algorithm. We will validate the algorithm for granular gas simulations and prove its scalability on up to 131 072 processor cores. Additionally, we will show several parallel granular material simulations both with spherical and non-spherical granular particles.},
	Author = {Iglberger, K. and R{\"{u}}de, U.},
	Doi = {10.1007/s00450-010-0114-4},
	File = {:Users/konstantinos/Google Drive/papers/Massively parallel granular flow simulations with non-spherical particles{\_}Iglberger, R{\"{u}}de.pdf:pdf},
	Isbn = {0045001001144},
	Issn = {18652034},
	Journal = {Computer Science - Research and Development},
	Keywords = {Granular media,Large-scale,MPI,Massively parallel,Parallel algorithms,Parallel frameworks,Parallelization,Rigid body dynamics},
	Number = {1-2},
	Pages = {105--113},
	Title = {{Massively parallel granular flow simulations with non-spherical particles}},
	Volume = {25},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s00450-010-0114-4}}

@article{Koziara2010,
	Abstract = {Simple and efficient way of integrating rigid rotations is presented. The algorithm is stable, second-order accurate, and in its explicit version involves evaluation of only two exponential maps per time step. The semi-explicit version of the proposed scheme improves upon the long-term stability, while it retains the explicitness in the force evaluation. The algebraic structure of both schemes makes them suitable forthe analysis of constrained multi-body systems. The explicit algorithm is specifically aimed at the analysis involving small incremental rotations, where its modest computational cost becomes the major advantage. The semi-explicit scheme naturally broadens the scope of possible applications.},
	Author = {Koziara, Tomasz and Bi{\'{c}}ani{\'{c}}, Nenad},
	Doi = {10.1002/nme.2711},
	File = {:Users/konstantinos/Google Drive/papers/Simple and efficient integration of rigid rotations suitable for constraint solvers{\_}Koziara, Bi{\'{c}}ani{\'{c}}.pdf:pdf},
	Issn = {00295981},
	Journal = {International Journal for Numerical Methods in Engineering},
	Keywords = {Constrained motion,Explicit scheme,Rigid rotations,Time integration},
	Number = {9},
	Pages = {1073--1092},
	Title = {{Simple and efficient integration of rigid rotations suitable for constraint solvers}},
	Volume = {81},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/nme.2711}}

@article{Wachs2012,
	Abstract = {We suggest a novel variant of Discrete Element Method (DEM) to simulate the flow dynamics of granular material made of non-spherical particles. Our approach is limited to particles of convex shape but permits to consider any combination of shape and size, which makes it very versatile. The contact detection strategy relies on the use of the Gilbert-Johnson-Keerthi algorithm to compute the distance between two convex bodies. The validation of the method is based on two different test cases in three dimensions: (i) the formation of a packed pile in a cylindrical container and (ii) flow dynamics in a horizontal rotating drum. In both cases, four shapes are investigated: a sphere, a cylinder, a cube and a tetrahedron. We evidence that our numerical code, Grains3D, supplies reliable and reasonably accurate computed solutions, both for spherical and non-spherical particles. In particular, in the latter case, we show how angularity promotes the appearance of the avalanching regime at relatively high Froude number compared to the spherical counterpart. {\copyright} 2012 Elsevier B.V..},
	Author = {Wachs, Anthony and Girolami, Laurence and Vinay, Guillaume and Ferrer, Gilles},
	Doi = {10.1016/j.powtec.2012.03.023},
	File = {:Users/konstantinos/Google Drive/papers/Grains3D, a flexible DEM approach for particles of arbitrary convex shape - Part I Numerical model and validations{\_}Wachs et al.pdf:pdf},
	Isbn = {00325910},
	Issn = {00325910},
	Journal = {Powder Technology},
	Keywords = {Compacity,Convex shape,Discrete Element Method,Granular flow,Rotating drum},
	Pages = {374--389},
	Publisher = {Elsevier B.V.},
	Title = {{Grains3D, a flexible DEM approach for particles of arbitrary convex shape - Part I: Numerical model and validations}},
	Url = {http://dx.doi.org/10.1016/j.powtec.2012.03.023},
	Volume = {224},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.powtec.2012.03.023}}

@article{Jensen2014,
	Author = {Jensen, Adrian and Fraser, Kirk and Laird, George},
	File = {:Users/konstantinos/Google Drive/papers/Improving the Precision of Discrete Element Simulations through Calibration Models{\_}Jensen, Fraser, Laird.pdf:pdf},
	Journal = {13th International LS-DYNA Users Conference},
	Keywords = {calibration,discrete element method,granular material flow,improving simulation precision,ls-dyna,users},
	Pages = {1--12},
	Title = {{Improving the Precision of Discrete Element Simulations through Calibration Models}},
	Year = {2014}}

@article{Kaczmarczyk2011,
	Abstract = {This paper presents theory for the Lagrange co-rotational (CR) formulation of finite elements in the geometrically nonlinear analysis of 3D structures. In this paper strains are assumed to be small while the magnitude of rotations from the reference configuration is not restricted. A new best fit rotator and consistent spin filter are derived. Lagrange CR formulation is applied with Hybrid Trefftz Stress elements, although presented methodology can be applied to arbitrary problem formulation and discretization technique, f.e. finite volume methods and lattice models, discreet element methods. Efficiency of CR formulation can be utilized in post-buckling stability analysis, damage and fracture mechanics, modelling of dynamic fragmentation of bodies made from quasi-brittle materials, solid fluid interactions and analysis of post-stressed structures, discreet body dynamics.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:1110.5321v1},
	Author = {Kaczmarczyk, {\AA} and Koziara, Tomasz and Pearce, Cj},
	Eprint = {arXiv:1110.5321v1},
	File = {:Users/konstantinos/Google Drive/papers/Corotational formulation for 3d solids. An analysis of geometrically nonlinear foam deformation{\_}Kaczmarczyk, Koziara, Pearce.pdf:pdf},
	Journal = {arXiv preprint arXiv:1110.5321},
	Keywords = {foam,geometrically,lagrange and co-rotated formulation,large rotations,nonlinear,trefftz elements},
	Pages = {1--23},
	Title = {{Corotational formulation for 3d solids. An analysis of geometrically nonlinear foam deformation}},
	Url = {http://arxiv.org/abs/1110.5321},
	Year = {2011},
	Bdsk-Url-1 = {http://arxiv.org/abs/1110.5321}}

@article{Koziara2008,
	Abstract = {Recently developed semismooth Newton approach is adopted in the context of the frictional contact between three-dimensional pseudo-rigid bodies. The Signorini-Coulomb problem is formulated according to the formalism of the Contact Dynamics method. Hybrid linearisation, penalty scaling and line search techniques are combined as the global convergence enhancements of the Newton algorithm. Quasi-static simulations of dry masonry assemblies exemplify performance of the presented framework. {\copyright} 2008 Elsevier B.V. All rights reserved.},
	Author = {Koziara, Tomasz and Bi{\'{c}}ani{\'{c}}, Nenad},
	Doi = {10.1016/j.cma.2008.01.006},
	File = {:Users/konstantinos/Google Drive/papers/Semismooth Newton method for frictional contact between pseudo-rigid bodies{\_}Koziara, Bi{\'{c}}ani{\'{c}}.pdf:pdf},
	Issn = {00457825},
	Journal = {Computer Methods in Applied Mechanics and Engineering},
	Keywords = {Finite kinematics,Frictional contact,Multi-body contact,Pseudo-rigid body,Semismooth Newton,Signorini-Coulomb problem},
	Number = {33-40},
	Pages = {2763--2777},
	Title = {{Semismooth Newton method for frictional contact between pseudo-rigid bodies}},
	Volume = {197},
	Year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.cma.2008.01.006}}

@article{Bridson2002,
	Abstract = {We present an algorithm to efficiently and robustly process collisions, contact and friction in cloth simulation. It works with any technique for simulating the internal dynamics of the cloth, and allows true modeling of cloth thickness. We also show how our simulation data can be post-processed with a collision-aware subdivision scheme to produce smooth and interference free data for rendering.},
	Author = {Bridson, Robert and Fedkiw, Ronald and Anderson, John},
	Doi = {10.1145/566654.566623},
	File = {:Users/konstantinos/Google Drive/papers/Robust treatment of collisions, contact and friction for cloth animation{\_}Bridson, Fedkiw, Anderson.pdf:pdf},
	Isbn = {1-58113-521-1},
	Issn = {07300301},
	Journal = {ACM Transactions on Graphics},
	Keywords = {cloth,collision detection,collision response,contacts,kinetic friction,physically based animation,static friction},
	Number = {3},
	Pages = {594--603},
	Title = {{Robust treatment of collisions, contact and friction for cloth animation}},
	Volume = {21},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/566654.566623}}

@article{Harmon2012,
	Abstract = {We develop a method for reliable simulation of elastica in com- plex contact scenarios. Our focus is on firmly establishing three parameter-independent guarantees: that simulations of well- posed problems (a) have no interpenetrations, (b) obey causality, momentum- and energy-conservation laws, and (c) complete in fi- nite time. We achieve these guarantees through a novel synthe- sis of asynchronous variational integrators, kinetic data structures, and a discretization of the contact barrier potential by an infinite sum of nested quadratic potentials. In a series of two- and three- dimensional examples, we illustrate that this method more easily handles challenging problems involving complex contact geome- tries, sharp features, and sliding during extremely tight contact.},
	Author = {Harmon, David and Vouga, Etienne and Smith, Breannan and Tamstorf, Rasmus and Grinspun, Eitan},
	Doi = {10.1145/2133806.2133828},
	File = {:Users/konstantinos/Google Drive/papers/Asynchronous contact mechanics{\_}Harmon et al.pdf:pdf},
	Isbn = {978-1-60558-726-4},
	Issn = {00010782},
	Journal = {Communications of the ACM},
	Keywords = {and engineering,collision,contact,contact scenarios is critical,entertainment,ing,product design,robust simulation of complex,simulation,symplectic,to applications spanning graphics,train-,variational,virtual worlds},
	Number = {3},
	Pages = {102},
	Title = {{Asynchronous contact mechanics}},
	Volume = {55},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2133806.2133828}}

@article{Harmon2008,
	Abstract = {Robust treatment of complex collisions is a challenging problem in cloth simulation. Some state of the art methods resolve collisions iteratively, invoking a fail-safe when a bound on iteration count is exceeded. The best-known fail-safe rigidifies the contact region, causing simulation artifacts. We present a fail-safe that cancels impact but not sliding motion, considerably reducing artificial dissipation. We equip the proposed fail-safe with an approximation of Coulomb friction, allowing finer control of sliding dissipation.},
	Author = {Harmon, David and Vouga, Etienne and Tamstorf, Rasmus and Grinspun, Eitan},
	Doi = {10.1145/1360612.1360622},
	File = {:Users/konstantinos/Google Drive/papers/Robust treatment of simultaneous collisions{\_}Harmon et al.pdf:pdf},
	Isbn = {9781450301121},
	Issn = {07300301},
	Journal = {ACM Transactions on Graphics},
	Keywords = {an improved,cloth,collision,collisions,configuration space,contact,given the time step,projection method for resolving,resolution,shells,simulation,simultaneous,tangential motion as possible,this method serves as,we present a simple,while preserving as much},
	Number = {3},
	Pages = {1},
	Title = {{Robust treatment of simultaneous collisions}},
	Volume = {27},
	Year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1360612.1360622}}

@article{Koziara2011,
	Abstract = {Solfec is a computational code aimed at simulation of constrained multibody systems on distributed memory parallel computers. It implements an instance of the Contact Dynamics (CD) method by Moreau and Jean, hence the constraints are handled implicitly. One of the main goals of the software is to provide a user friendly platform for testing formulations and solution methods for the (dynamic) frictional contact problem. It is also meant to serve as a development platform for other aspects of time-stepping methods (e.g. contact detection, time integration, kinematic models). The purpose of this communication is to outline the algorithmic ideas behind Solfec, with an emphasis on the Gauss--Seidel constraints solver, a classical element of CD, efficiently implemented on a distributed memory model. The remaining topics include a dynamic domain decomposition balancing the computational load of the overall algorithm, and an accuracy measure for the frictional contact constraints. Solfec is an open-source software and can be downloaded from http://code.google.com/p/solfec.},
	Author = {Koziara, T. and Bicani, N.},
	Doi = {10.1002/nme.3158},
	File = {:Users/konstantinos/Google Drive/papers/A distributed memory parallel multibody Contact Dynamics code{\_}Koziara, Bicani.pdf:pdf},
	Issn = {00295981},
	Journal = {International Journal for Numerical Methods in Engineering},
	Keywords = {Contact dynamics,Distributed memory gauss-seidel,Multibody contact},
	Number = {1-5},
	Pages = {437--456},
	Title = {{A distributed memory parallel multibody Contact Dynamics code}},
	Volume = {87},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/nme.3158}}

@article{Rycroft2012,
	Author = {Rycroft, Chris H and Lind, Terttaliisa and G{\"{u}}ntay, Salih and Dehbi, Abdel},
	File = {:Users/konstantinos/Google Drive/papers/Granular flow in pebble bed reactors dust generation and scaling{\_}Rycroft et al.pdf:pdf},
	Isbn = {9781622762101},
	Keywords = {dust generation,granular flow,numerical methods},
	Pages = {447--455},
	Title = {{Granular flow in pebble bed reactors : dust generation and scaling}},
	Year = {2012}}

@article{Iglberger2011,
	Author = {Iglberger, Klaus and R{\"{u}}de, Ulrich},
	Doi = {10.1007/s11044-010-9212-0},
	File = {:Users/konstantinos/Google Drive/papers/Large-scale rigid body simulations{\_}Iglberger, R{\"{u}}de.pdf:pdf},
	Isbn = {1384-5640},
	Issn = {13845640},
	Journal = {Multibody System Dynamics},
	Keywords = {Large-scale,MPI,Massively parallel,Parallel algorithms,Parallel frameworks,Parallel programming,Parallelization,Rigid body dynamics},
	Number = {1},
	Pages = {81--95},
	Title = {{Large-scale rigid body simulations}},
	Volume = {25},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s11044-010-9212-0}}

@article{Ni2015,
	Author = {Ni, Xiang and Kale, Laxmikant V. and Tamstorf, Rasmus},
	Doi = {10.1109/IPDPS.2015.45},
	File = {:Users/konstantinos/Google Drive/papers/Scalable Asynchronous Contact Mechanics Using Charm{\_}Ni, Kale, Tamstorf.pdf:pdf},
	Isbn = {978-1-4799-8649-1},
	Journal = {2015 IEEE International Parallel and Distributed Processing Symposium},
	Pages = {677--686},
	Title = {{Scalable Asynchronous Contact Mechanics Using Charm++}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7161555},
	Year = {2015},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7161555},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/IPDPS.2015.45}}

@article{Iglberger2009,
	Abstract = {For decades, rigid body dynamics has been used in several active research fields to simulate the behavior of completely undeformable, rigid bodies. Due to the focus of the simulations to either high physical accuracy or real time environments, the state-of-the-art algorithms cannot be used in excess of several thousand rigid bodies. Either the complexity of the algorithms would result in infeasible runtimes, or the simulation could no longer satisfy the real time aspects.   In this paper we present a novel approach for large-scale rigid body dynamics simulations. The presented algorithm enables for the first time rigid body simulations of several million rigid bodies. We describe in detail the parallel rigid body algorithm and its necessary extensions for a large-scale MPI parallelization and analyze the parallel algorithm by means of a particular simulation scenario.},
	Author = {Iglberger, Klaus and R{\"{u}}de, Ulrich},
	Doi = {10.1007/s00450-009-0066-8},
	File = {:Users/konstantinos/Google Drive/papers/Massively parallel rigid body dynamics simulations{\_}Iglberger, R{\"{u}}de.pdf:pdf},
	Issn = {18652034},
	Journal = {Computer Science - Research and Development},
	Keywords = {Large-scale,MPI,Massively parallel,Parallel algorithms,Parallel frameworks,Parallel programming,Parallelization,Rigid body dynamics},
	Number = {3-4},
	Pages = {159--167},
	Title = {{Massively parallel rigid body dynamics simulations}},
	Volume = {23},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s00450-009-0066-8}}

@article{Kaufman2005a,
	Abstract = {We describe an efficient algorithm for the simulation of large sets of non-convex rigid bodies. The algorithm finds a simultaneous solution for a multi-body system that is linear in the total number of contacts detected in each iteration. We employ a novel contact model that uses mass, location, and velocity information from all contacts, at the moment of maximum compression, to constrain rigid body velocities. We also develop a new friction model in the configuration space of rigid bodies. These models are used to compute the feasible velocity and the fractional response of each body. Implementation is simple and leads to a fast rigid body simulator that computes steps on the order of seconds for simulations involving over one thousand non-convex objects in high contact configurations. Copyright {\copyright} 2005 by the Association for Computing Machinery, Inc.},
	Author = {Kaufman, Danny M. and Edmunds, Timothy and Pai, Dinesh K.},
	Doi = {10.1145/1073204.1073295},
	File = {:Users/konstantinos/Google Drive/papers/Fast frictional dynamics for rigid bodies{\_}Kaufman, Edmunds, Pai(2).pdf:pdf},
	Isbn = {9780000000002},
	Issn = {07300301},
	Journal = {ACM Transactions on Graphics},
	Keywords = {contact,friction,non-smooth dynamics,rigid bodies},
	Number = {3},
	Pages = {946},
	Title = {{Fast frictional dynamics for rigid bodies}},
	Volume = {24},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1073204.1073295}}

@article{Solberg2000,
	Abstract = {This paper deals with the impact behavior of elastic pseudo-rigid bodies. It is shown that in the case of a spherically symmetric, linearly elastic pseudo-rigid body impacting on a rigid foundation, energy conservation necessitates the existence of multiple impact events. A comparison is made with the dynamic Hertzian theory in terms of the coefficient of restitution and the duration of impact. In addition, the chaotic nature of the long-term dynamics of this system is explored qualitatively.},
	Author = {Solberg, Jerome M. and Papadopoulos, Panayiotis},
	Doi = {10.1016/S0020-7225(99)00043-9},
	File = {:Users/konstantinos/Google Drive/papers/Impact of an elastic pseudo-rigid body on a rigid foundation{\_}Solberg, Papadopoulos.pdf:pdf},
	Issn = {00207225},
	Journal = {International Journal of Engineering Science},
	Keywords = {elasticity,impact,pseudo-rigid bodies},
	Number = {6},
	Pages = {589--603},
	Title = {{Impact of an elastic pseudo-rigid body on a rigid foundation}},
	Volume = {38},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0020-7225(99)00043-9}}

@article{AlonsoMarroqu2013,
	Abstract = {Responding to a lack in the literature, mechanical properties of polygonal wood particles are determined for use in a discrete element model (DEM) for flow analysis in silos, and some methods are proposed for determining such parameters. The parameters arrived at here have also formed part of the input to the SPOLY software, developed in-house to compute the DEM model with spheropolyhedron elements. The model is validated using a 2D physical model, where 'prismatic' particles with polygonal cross sections are placed inside a silo with variable aperture and hopper angle. Validation includes comparison of flow-rates computed by SPOLY, displacement profiles, and clogging thresholds with experimental results. The good agreement that emerges will encourage future use of miniature triaxial tests, grain-surface profilometry, inclined slope tests, and numerical analysis of the intragranular stresses-toward a direct construction of the contact-deformation relations required in realistic DEM modelling of particle flow with angular-shaped particles. [ABSTRACT FROM AUTHOR]},
	Author = {Alonso-Marroquin, Fernando and Ramirez-Gomez, Alvaro and Gonzalez-Montellano, Carlos and Balaam, Nigel and Hanaor, Dorian A H and Flores-Johnson, E. A. and Gan, Yixiang and Chen, Shumiao and Shen, Luming},
	Doi = {10.1007/s10035-013-0443-7},
	File = {:Users/konstantinos/Google Drive/papers/Experimental and numerical determination of mechanical properties of polygonal wood particles and their flow analysis in silos{\_}Alonso-Ma.pdf:pdf},
	Issn = {14345021},
	Journal = {Granular Matter},
	Keywords = {DEM,Mechanical properties,Polygonal particle,SPOLY software,Silo,Wood flow},
	Number = {6},
	Pages = {811--826},
	Title = {{Experimental and numerical determination of mechanical properties of polygonal wood particles and their flow analysis in silos}},
	Volume = {15},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10035-013-0443-7}}

@article{Eberly1999,
	Author = {Eberly, David},
	File = {:Users/konstantinos/Google Drive/papers/Distance between point and triangle in 3D{\_}Eberly.pdf:pdf},
	Journal = {Magic Software{\ldots}},
	Pages = {1--6},
	Title = {{Distance between point and triangle in 3D}},
	Url = {http://continuous-collision-detection.googlecode.com/svn/trunk/Docs/Bounding{\_}Volume{\_}Hierarchies/ElementalTests/DistancePoint3Triangle3.pdf},
	Year = {1999},
	Bdsk-Url-1 = {http://continuous-collision-detection.googlecode.com/svn/trunk/Docs/Bounding%7B%5C_%7DVolume%7B%5C_%7DHierarchies/ElementalTests/DistancePoint3Triangle3.pdf}}

@article{Smith1995,
	Author = {Smith, Alice E and Coit, David W},
	File = {:Users/konstantinos/Google Drive/papers/Penalty functions{\_}Smith, Coit.pdf:pdf},
	Journal = {Handbook of Evolutionary Computation},
	Number = {1},
	Pages = {C5},
	Title = {{Penalty functions}},
	Volume = {97},
	Year = {1995}}

@misc{Ericson2005,
	Author = {Ericson, C},
	Booktitle = {Collision Detection and Proximity Queries - SIGGRAPH 2004 Course},
	File = {:Users/konstantinos/Google Drive/papers/The Gilbert-Johnson-Keerthi algorithm{\_}Ericson.pdf:pdf},
	Title = {{The Gilbert-Johnson-Keerthi algorithm}},
	Url = {http://realtimecollisiondetection.net/pubs/SIGGRAPH04{\_}Ericson{\_}GJK{\_}notes.pdf},
	Year = {2005},
	Bdsk-Url-1 = {http://realtimecollisiondetection.net/pubs/SIGGRAPH04%7B%5C_%7DEricson%7B%5C_%7DGJK%7B%5C_%7Dnotes.pdf}}

@article{Tropp2006,
	Abstract = {The triangle-to-triangle intersection test is a basic component of all collision detection data structures and algorithms. This paper presents a fast method for testing whether two triangles embedded in three dimensions intersect. Our technique solves the basic sets of linear equations associated with the problem and exploits the strong relations between these sets to speed up their solution. Moreover, unlike previous techniques, with very little additional cost, the exact intersection coordinates can be determined. Finally, our technique uses general principles that can be applied to similar problems such as rectangle-to-rectangle intersection tests, and generally to problems where several equation sets are strongly related. We show that our algorithm saves about 20{\%} of the mathematical operations used by the best previous triangle-to-triangle intersection algorithm. Our experiments also show that it runs 18.9{\%} faster than the fastest previous algorithm on average for typical scenarios of collision detection (on Pentium 4).},
	Author = {Tropp, Oren and Tal, Ayellet and Shimshoni, Ilan},
	Doi = {10.1002/cav.115},
	File = {:Users/konstantinos/Google Drive/papers/A fast triangle to triangle intersection test for collision detection{\_}Tropp, Tal, Shimshoni.pdf:pdf},
	Issn = {15464261},
	Journal = {Computer Animation and Virtual Worlds},
	Keywords = {Collision detection,Triangle to triangle intersection},
	Number = {5},
	Pages = {527--535},
	Title = {{A fast triangle to triangle intersection test for collision detection}},
	Volume = {17},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/cav.115}}

@article{Hansen2000,
	Abstract = {The L-curve is a log-log plot of the norm of a regularized solution versus the norm of the corresponding residual norm. It is a convenient graphical tool for displaying the trade-off between the size of a regularized solution and its fit to the given data, as the regularization parameter varies. The L-curve thus gives insight into the regularizing properties of the underlying regularization method, and it is an aid in choosing an appropriate regularization parameter for the given data. In this chapter we summarize the main properties of the L-curve, and demonstrate by examples its usefulness and its limitations both as an analysis tool and as a method for choosing the regularization parameter. 1 Introduction Practically all regularization methods for computing stable solutions to inverse problems involve a trade-off between the "size" of the regularized solution and the quality of the fit that it provides to the given data. What distinguishes the various regularization methods is how...},
	Author = {Hansen, P C},
	Doi = {10.1.1.33.6040},
	File = {:Users/konstantinos/Google Drive/papers/The L-Curve and its Use in the Numerical Treatment of Inverse Problems{\_}Hansen.pdf:pdf},
	Journal = {in Computational Inverse Problems in Electrocardiology, ed. P. Johnston, Advances in Computational Bioengineering},
	Keywords = {inverse,l-curve,regularization-parameter-selection},
	Pages = {119--142},
	Title = {{The L-Curve and its Use in the Numerical Treatment of Inverse Problems}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.6040},
	Volume = {4},
	Year = {2000},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.6040},
	Bdsk-Url-2 = {http://dx.doi.org/10.1.1.33.6040}}

@article{Freund1968,
	Author = {Freund, Robert M},
	File = {:Users/konstantinos/Google Drive/papers/Algorithms for Constrained Optimization A . 1 Penalty and Barrier Methods{\_}Freund.pdf:pdf},
	Isbn = {9783319018805},
	Journal = {Methods},
	Number = {23},
	Pages = {55--58},
	Title = {{Algorithms for Constrained Optimization A . 1 Penalty and Barrier Methods}},
	Url = {http://ocw.cupide.org/NR/rdonlyres/Sloan-School-of-Management/15-084JSpring2004/A8E10BC8-6B04-4D64-94F2-FB697408B1FF/0/lec10{\_}penalty{\_}mt.pdf},
	Year = {1968},
	Bdsk-Url-1 = {http://ocw.cupide.org/NR/rdonlyres/Sloan-School-of-Management/15-084JSpring2004/A8E10BC8-6B04-4D64-94F2-FB697408B1FF/0/lec10%7B%5C_%7Dpenalty%7B%5C_%7Dmt.pdf}}

@article{Coffey2002,
	Author = {Coffey, T.S. and Kelley, C.T. and Keyes, D.E.},
	Doi = {10.1137/S106482750241044X},
	File = {:Users/konstantinos/Google Drive/papers/Pseduo-Transient Continuation and Differential-Algebraic Equations{\_}Coffey, Kelley, Keyes.pdf:pdf},
	Journal = {SIAM Journal of Scientific Computing},
	Keywords = {differential-algebraic equations,global convergence,nonlinear equations,pseudo-transient continuation,steady-state solutions},
	Pages = {1--13},
	Title = {{Pseduo-Transient Continuation and Differential-Algebraic Equations}},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1137/S106482750241044X}}

@article{Plimpton1995,
	Abstract = {Three parallel algorithms for classical molecular dynamics are presented. The first assigns each processor a fixed subset of atoms; the second assigns each a fixed subset of inter--atomic forces to compute; the third assigns each a fixed spatial region. The algorithms are suitable for molecular dynamics models which can be difficult to parallelize efficiently --- those with short--range forces where the neighbors of each atom change rapidly. They can be implemented on any distributed--memory parallel machine which allows for message--passing of data between independently executing processors. The algorithms are tested on a standard Lennard--Jones benchmark problem for system sizes ranging from 500 to 100,000,000 atoms on several parallel supercomputers---the nCUBE 2, Intel iPSC/860 and Paragon, and Cray T3D. Comparing the results to the fastest reported vectorized Cray Y--MP and C90 algorithm shows that the current generation of parallel machines is competitive with conventional vector supercomputers even for small problems. For large problems, the spatial algorithm achieves parallel efficiencies of 90{\%} and a 1840--node Intel Paragon performs up to 165 faster than a single Cray C90 processor. Trade--offs between the three algorithms and guidelines for adapting them to more complex molecular dynamics simulations are also discussed.},
	Author = {Plimpton, Steve},
	Doi = {10.1006/jcph.1995.1039},
	File = {:Users/konstantinos/Google Drive/papers/Fast Parallel Algorithms for Short -- Range Molecular Dynamics{\_}Plimpton.pdf:pdf},
	Isbn = {0021-9991},
	Issn = {00219991},
	Journal = {Jounal of Computational Physics},
	Keywords = {body problem,molecular dynamics,n,parallel computing},
	Number = {June 1994},
	Pages = {1--42},
	Title = {{Fast Parallel Algorithms for Short -- Range Molecular Dynamics}},
	Url = {http://lammps.sandia.gov},
	Volume = {117},
	Year = {1995},
	Bdsk-Url-1 = {http://lammps.sandia.gov},
	Bdsk-Url-2 = {http://dx.doi.org/10.1006/jcph.1995.1039}}

@article{Shaw2005,
	Abstract = {Classical molecular dynamics simulations of biological macromolecules in explicitly modeled solvent typically require the evaluation of interactions between all pairs of atoms separated by no more than some distance R, with more distant interactions handled using some less expensive method. Performing such simulations for periods on the order of a millisecond is likely to require the use of massive parallelism. The extent to which such simulations can be efficiently parallelized, however, has historically been limited by the time required for interprocessor communication. This article introduces a new method for the parallel evaluation of distance-limited pairwise particle interactions that significantly reduces the amount of data transferred between processors by comparison with traditional methods. Specifically, the amount of data transferred into and out of a given processor scales as O(R(3/2)p(-1/2)), where p is the number of processors, and with constant factors that should yield a substantial performance advantage in practice.},
	Author = {Shaw, David E.},
	Doi = {10.1002/jcc.20267},
	File = {:Users/konstantinos/Google Drive/papers/A fast, scalable method for the parallel evaluation of distance-limited pairwise particle interactions{\_}Shaw.pdf:pdf},
	Isbn = {0192-8651},
	Issn = {01928651},
	Journal = {Journal of Computational Chemistry},
	Keywords = {Molecular dynamics,Molecular simulation,Pairwise particle interactions,Parallel computing,n-body problem},
	Number = {13},
	Pages = {1318--1328},
	Pmid = {16013057},
	Title = {{A fast, scalable method for the parallel evaluation of distance-limited pairwise particle interactions}},
	Volume = {26},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/jcc.20267}}

@article{Eckhardt2014,
	Author = {Eckhardt, Wolfgang},
	File = {:Users/konstantinos/Google Drive/papers/Efficient HPC Implementations for Large-Scale Molecular Simulation in Process Engineering{\_}Eckhardt.pdf:pdf},
	Title = {{Efficient HPC Implementations for Large-Scale Molecular Simulation in Process Engineering}},
	Year = {2014}}

@article{Bowers2007,
	Abstract = {Particle simulations in fields ranging from biochemistry to astrophysics require the evaluation of interactions between all pairs of particles separated by less than some fixed interaction radius. The applicability of such simulations is often limited by the time required for calculation, but the use of massive parallelism to accelerate these computations is typically limited by inter-processor communication requirements. Recently, Snir [M. Snir, A note on N-body computations with cutoffs, Theor. Comput. Syst. 37 (2004) 295-318] and Shaw [D.E. Shaw, A fast, scalable method for the parallel evaluation of distance-limited pairwise particle interactions, J. Comput. Chem. 26 (2005) 1318-1328] independently introduced two distinct methods that offer asymptotic reductions in the amount of data transferred between processors. In the present paper, we show that these schemes represent special cases of a more general class of methods, and introduce several new algorithms in this class that offer practical advantages over all previously described methods for a wide range of problem parameters. We also show that several of these algorithms approach an approximate lower bound on inter-processor data transfer. ?? 2006 Elsevier Inc. All rights reserved.},
	Author = {Bowers, Kevin J. and Dror, Ron O. and Shaw, David E.},
	Doi = {10.1016/j.jcp.2006.06.014},
	File = {:Users/konstantinos/Google Drive/papers/Zonal methods for the parallel execution of range-limited N-body simulations{\_}Bowers, Dror, Shaw.pdf:pdf},
	Isbn = {00219991},
	Issn = {00219991},
	Journal = {Journal of Computational Physics},
	Keywords = {Molecular dynamics,Molecular simulation,N-body problem,Pairwise particle interactions,Parallel computing},
	Number = {1},
	Pages = {303--329},
	Pmid = {244321000016},
	Title = {{Zonal methods for the parallel execution of range-limited N-body simulations}},
	Volume = {221},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.jcp.2006.06.014}}

@article{Gonnet2014,
	Abstract = {This paper describes a new fast and implicitly parallel approach to neighbor-finding in multiresolution smoothed particle hydrodynamics (SPH) simulations. This new approach is based on hierarchical cell decompositions and sorted interactions, within a task-based formulation. It is shown to be faster than traditional tree-based codes and to scale better than domain decomposition--based approaches on hybrid shared/distributed-memory parallel architectures, e.g., clusters of multicores, achieving a {\$}40\backslashtimes{\$} speedup over the Gadget-2 simulation code.},
	Archiveprefix = {arXiv},
	Arxivid = {1404.2303},
	Author = {Gonnet, Pedro},
	Doi = {10.1137/140964266},
	Eprint = {1404.2303},
	File = {:Users/konstantinos/Google Drive/papers/Efficient and Scalable Algorithms for Smoothed Particle Hydrodynamics on Hybrid SharedDistributed-Memory Architectures{\_}Gonnet.pdf:pdf},
	Issn = {1064-8275},
	Journal = {SIAM Journal on Scientific Computing},
	Keywords = {15A09,15A15,15A23,multicores,simulation,smoothed particle hydrodynamics,task-based parallelism},
	Number = {1},
	Pages = {C95--C121},
	Title = {{Efficient and Scalable Algorithms for Smoothed Particle Hydrodynamics on Hybrid Shared/Distributed-Memory Architectures}},
	Url = {http://epubs.siam.org/doi/abs/10.1137/140964266},
	Volume = {37},
	Year = {2015},
	Bdsk-Url-1 = {http://epubs.siam.org/doi/abs/10.1137/140964266},
	Bdsk-Url-2 = {http://dx.doi.org/10.1137/140964266}}

@article{Brown2015,
	Author = {Brown, Russell A},
	File = {:Users/konstantinos/Google Drive/papers/Building a Balanced k-d Tree in O ( kn log n ) Time{\_}Brown.pdf:pdf},
	Number = {1},
	Pages = {50--68},
	Title = {{Building a Balanced k-d Tree in O ( kn log n ) Time}},
	Volume = {4},
	Year = {2015}}

@article{Juurlink,
	Author = {Juurlink, Ben},
	File = {:Users/konstantinos/Google Drive/papers/Performance Impact of Misaligned Accesses in SIMD Extensions{\_}Juurlink.pdf:pdf},
	Journal = {Computer Engineering},
	Keywords = {data alignment,multimedia extensions,simd},
	Pages = {334--342},
	Title = {{Performance Impact of Misaligned Accesses in SIMD Extensions}}}

@article{Dongarra2011,
	Abstract = {Over the last 20 years, the open-source community has provided more and more software on which the world's high-performance computing systems depend for performance and productivity. The community has invested millions of dollars and years of effort to build key components. However, although the investments in these separate software elements have been tremendously valuable, a great deal of productivity has also been lost because of the lack of planning, coordination, and key integration of technologies necessary to make them work together smoothly and efficiently, both within individual petascale systems and between different systems. It seems clear that this completely uncoordinated development model will not provide the software needed to support the unprecedented parallelism required for peta/ exascale computation on millions of cores, or the flexibility required to exploit new hardware models and features, such as transactional memory, speculative execution, and graphics processing units. This report describes the work of the community to prepare for the challenges of exascale computing, ultimately combing their efforts in a coordinated International Exascale Software Project.},
	Author = {Dongarra, J. and Beckman, P. and Moore, T. and Aerts, P. and Aloisio, G. and Andre, J.-C. and Barkai, D. and Berthou, J.-Y. and Boku, T. and Braunschweig, B. and Cappello, F. and Chapman, B. and {Xuebin Chi} and Choudhary, a. and Dosanjh, S. and Dunning, T. and Fiore, S. and Geist, a. and Gropp, B. and Harrison, R. and Hereld, M. and Heroux, M. and Hoisie, a. and Hotta, K. and {Zhong Jin} and Ishikawa, Y. and Johnson, F. and Kale, S. and Kenway, R. and Keyes, D. and Kramer, B. and Labarta, J. and Lichnewsky, a. and Lippert, T. and Lucas, B. and Maccabe, B. and Matsuoka, S. and Messina, P. and Michielse, P. and Mohr, B. and Mueller, M. S. and Nagel, W. E. and Nakashima, H. and Papka, M. E. and Reed, D. and Sato, M. and Seidel, E. and Shalf, J. and Skinner, D. and Snir, M. and Sterling, T. and Stevens, R. and Streitz, F. and Sugar, B. and Sumimoto, S. and Tang, W. and Taylor, J. and Thakur, R. and Trefethen, a. and Valero, M. and van der Steen, a. and Vetter, J. and Williams, P. and Wisniewski, R. and Yelick, K.},
	Doi = {10.1177/1094342010391989},
	File = {:Users/konstantinos/Google Drive/papers/The International Exascale Software Project roadmap{\_}Dongarra et al.pdf:pdf},
	Isbn = {1094-3420},
	Issn = {1094-3420},
	Journal = {International Journal of High Performance Computing Applications},
	Keywords = {exascale computing,high-performance computing,software stack},
	Number = {1},
	Pages = {3--60},
	Pmid = {2675086881372247371},
	Title = {{The International Exascale Software Project roadmap}},
	Volume = {25},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1177/1094342010391989}}

@article{Tian,
	Abstract = {The relentless pace of Moore's Law will lead to modern multi-core processors, coprocessors and GPU designs with extensive on-die integration of SIMD execution units on CPU and GPU cores to achieve better performance and power efficiency. To make efficient use of the underlying SIMD hardware, utilizing its wide vector registers and SIMD instructions such as Xeon Phi{\texttrademark}, SIMD vectorization plays a key role of converting plain scalar C/C++ code into SIMD code that operating on vectors of data each holding one or more elements. Intel{\textregistered} Xeon Phi{\texttrademark} coprocessor is based on the Intel{\textregistered} Many Integrated Core (Intel{\textregistered} MIC) architecture, which is an innovative new processor architecture that combines abundant thread parallelism with long SIMD vector units. Efficiently exploiting SIMD vector units is one of the most important aspects in achieving high performance of the application code running on Intel{\textregistered} Xeon Phi{\texttrademark} coprocessors. In this paper, we present several effective SIMD vectorization techniques such as less-than-full-vector loop vectorization, Intel{\textregistered} MIC specific alignment optimization, and small matrix transpose/multiplication 2-D vectorization implemented in the Intel{\textregistered} C/C++ and Fortran production compilers for Intel{\textregistered} Xeon Phi{\texttrademark} coprocessors. A set of workloads from several application domains is employed to conduct the performance study of our SIMD vectorization techniques. The performance results show that we achieved up to 12.5x performance gain on the Intel{\textregistered} Xeon Phi{\texttrademark} coprocessor. We also demonstrate a 2000x performance speedup from the seamless integration of SIMD vectorization and parallelization.},
	Author = {Tian, Xinmin and Saito, Hideki and Preis, Serguei V. and Garcia, Eric N. and Kozhukhov, Sergey S. and Masten, Matt and Cherkasov, Aleksei G. and Panchenko, Nikolay},
	Doi = {10.1155/2015/269764},
	File = {:Users/konstantinos/Google Drive/papers/Effective SIMD Vectorization for Intel Xeon Phi Coprocessors{\_}Tian et al.pdf:pdf},
	Isbn = {978-0-7695-4979-8},
	Issn = {10589244},
	Journal = {Scientific Programming},
	Keywords = {compiler optimization,coprocessor,intel,mic architecture,simd vectorization,xeon phi},
	Title = {{Effective SIMD Vectorization for Intel Xeon Phi Coprocessors}},
	Volume = {2015},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1155/2015/269764}}

@article{Franchetti2008,
	Abstract = {This paper introduces a method to generate efficient vectorized implementations of small stride permutations using only vector load and vector shuffle instructions. These permutations are crucial for high-performance numerical kernels including the fast Fourier transform. Our generator takes as input only the specification of the target platform's SIMD vector ISA and the desired permutation. The basic idea underlying our generator is to model vector instructions as matrices and sequences of vector instructions as matrix formulas using the Kronecker product formalism. We design a rewriting system and a search mechanism that applies matrix identities to generate those matrix formulas that have vector structure and minimize a cost measure that we define. The formula is then translated into the actual vector program for the specified permutation. For three important classes of permutations, we show that our method yields a solution with the minimal number of vector shuffles. Inserting into a fast Fourier transform yields a significant speedup.},
	Author = {Franchetti, Franz and P{\"{u}}schel, Markus},
	Doi = {10.1007/978-3-540-78791-4{\_}8},
	File = {:Users/konstantinos/Google Drive/papers/Generating SIMD vectorized permutations{\_}Franchetti, P{\"{u}}schel.pdf:pdf},
	Isbn = {3540787909},
	Issn = {03029743},
	Journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Pages = {116--131},
	Title = {{Generating SIMD vectorized permutations}},
	Volume = {4959 LNCS},
	Year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-78791-4%7B%5C_%7D8}}

@article{Zomorodian2002,
	Abstract = {We present fast implementations of a hybrid algorithm for reporting box and cube intersections. Our algorithm initially takes a divide-and-conquer approach and switches to simpler algorithms for low numbers of boxes. We use our implementations as engines to solve problems about geometric primitives. We look at two such problems in the category of quality analysis of surface triangulations.},
	Author = {Zomorodian, Afra and Edelsbrunner, Herbert},
	Date-Modified = {2016-03-03 17:49:27 +0000},
	Doi = {10.1142/S0218195902000785},
	File = {:Users/konstantinos/Google Drive/papers/Fast Software for Box Intersections{\_}ZOMORODIAN, EDELSBRUNNER.pdf:pdf},
	Isbn = {1581132247},
	Issn = {0218-1959},
	Journal = {International Journal of Computational Geometry {\&} Applications},
	Keywords = {algorithms,box intersection,experimentation,implementation,quan-,range tree,segment tree,tification},
	Number = {01n02},
	Pages = {143--172},
	Title = {{Fast Software for Box Intersections}},
	Url = {http://www.worldscientific.com/doi/abs/10.1142/S0218195902000785},
	Volume = {12},
	Year = {2002},
	Bdsk-Url-1 = {http://www.worldscientific.com/doi/abs/10.1142/S0218195902000785},
	Bdsk-Url-2 = {http://dx.doi.org/10.1142/S0218195902000785}}

@article{Alvarez2007,
	Abstract = {Although SIMD extensions are a cost effective way to exploit the data level parallelism present in most media applications, we will show that they had have a very limited memory architecture with a weak support for unaligned memory accesses. In video codec, and other applications, the overhead for accessing unaligned positions without an efficient architecture support has a big performance penalty and in some cases makes vectorization counter-productive. In this paper we analyze the performance impact of extending the Altivec SIMD ISA with unaligned memory operations. Results show that for several kernels in the H.264/AVC media codec, unaligned access support provides a speedup up to 3.8times compared to the plain SIMD version, translating into an average of 1.2times in the entire application. In addition to providing a significant performance advantage, the use of unaligned memory instructions makes programming SIMD code much easier both for the manual developer and the auto vectorizing compiler},
	Author = {Alvarez, Mauricio and Salami, Esther and Ramirez, Alex and Valero, Mateo},
	Doi = {10.1109/ISPASS.2007.363737},
	File = {:Users/konstantinos/Google Drive/papers/Performance impact of unaligned memory operations in SIMD extensions for video codec applications{\_}Alvarez et al.pdf:pdf},
	Isbn = {1424410819},
	Journal = {ISPASS 2007: IEEE International Symposium on Performance Analysis of Systems and Software},
	Pages = {62--71},
	Title = {{Performance impact of unaligned memory operations in SIMD extensions for video codec applications}},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ISPASS.2007.363737}}

@article{Gaburov,
	Author = {Gaburov, Evghenii and Cavecchi, Yuri},
	File = {:Users/konstantinos/Google Drive/papers/XeonPhi Meets Astrophysical Fluid Dynamics{\_}Gaburov, Cavecchi.pdf:pdf},
	Pages = {1--7},
	Title = {{XeonPhi Meets Astrophysical Fluid Dynamics}}}

@article{Hoemmen2007,
	Author = {Hoemmen, Mark},
	File = {:Users/konstantinos/Google Drive/papers/Generating random numbers in parallel{\_}Hoemmen.pdf:pdf},
	Pages = {1--8},
	Title = {{Generating random numbers in parallel}},
	Year = {2007}}

@article{Eckhardt,
	Author = {Eckhardt, Wolfgang and Glas, Robert and Korzh, Denys and Wallner, Stefan},
	File = {:Users/konstantinos/Google Drive/papers/On-the-fly memory compression for multibody algorithms{\_}Eckhardt et al.pdf:pdf},
	Keywords = {communication-reducing algorithms,data compression,n-body simulation},
	Title = {{On-the-fly memory compression for multibody algorithms}}}

@article{Fleissner,
	Author = {Fleissner, Florian and Eberhard, Peter},
	File = {:Users/konstantinos/Google Drive/papers/Parallel Load Balanced Particle Simulation with Hierarchical Particle Grouping Strategies{\_}Fleissner, Eberhard.pdf:pdf},
	Pages = {33--44},
	Title = {{Parallel Load Balanced Particle Simulation with Hierarchical Particle Grouping Strategies}}}

@article{Eichenberger2004,
	Abstract = {When vectorizing for SIMD architectures that are commonly employed by today's multimedia extensions, one of the new challenges that arise is the handling of memory alignment. Prior research has focused primarily on vectorizing loops where all memory references are properly aligned. An important aspect of this problem, namely, how to vectorize misaligned memory references, still remains unaddressed. This paper presents a compilation scheme that systematically vectorizes loops in the presence of misaligned memory references. The core of our technique is to automatically reorganize data in registers to satisfy the alignment requirement imposed by the hardware. To reduce the data reorganization overhead, we propose several techniques to minimize the number of data reorganization operations generated. During the code generation, our algorithm also exploits temporal reuse when aligning references that access contiguous memory across loop iterations. Our code generation scheme guarantees to never load the same data associated with a single static access twice. Experimental results indicate near peak speedup factors, e.g., 3.71 for 4 data per vector and 6.06 for 8 data per vector, respectively, for a set of loops where 75{\%} or more of the static memory references are misaligned.},
	Author = {Eichenberger, Alexandre E. and Wu, Peng and O'Brien, Kevin},
	Doi = {10.1145/996893.996853},
	File = {:Users/konstantinos/Google Drive/papers/Vectorization for SIMD architectures with alignment constraints{\_}Eichenberger, Wu, O'Brien.pdf:pdf},
	Isbn = {1581138075},
	Issn = {03621340},
	Journal = {ACM SIGPLAN Notices},
	Keywords = {compiler,multimedia ex-,simd,simdization,vectorization},
	Number = {6},
	Pages = {82},
	Title = {{Vectorization for SIMD architectures with alignment constraints}},
	Volume = {39},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/996893.996853}}

@article{Hou,
	Author = {Hou, Kaixi and Wang, Hao and Feng, Wu-chun and Tech, Virginia},
	Doi = {10.1145/2751205.2751247},
	File = {:Users/konstantinos/Google Drive/papers/ASPaS A Framework for Automatic SIMDization of Parallel Sorting on x86-based Many-core Processors Categories and Subject Descriptors{\_}Ho.pdf:pdf},
	Isbn = {9781450335591},
	Keywords = {avx,isa,merge,mic,simd,sort,transpose,vectorization},
	Pages = {383--392},
	Title = {{ASPaS : A Framework for Automatic SIMDization of Parallel Sorting on x86-based Many-core Processors Categories and Subject Descriptors}},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2751205.2751247}}

@article{Lee2002,
	Abstract = {Abstract Load balanced parallel radix sort solved the load imbalance problem present in parallel radix sort . Redistributing the keys in each round of radix , each processor has exactly the same number of keys, thereby reducing the overall sorting time. Load balanced radix  ... $\backslash$n},
	Author = {Lee, Shin-jae and Jeon, Minsoo and Kim, Dongseung and Sohn, Andrew},
	Doi = {10.1006/jpdc.2001.1808},
	File = {:Users/konstantinos/Google Drive/papers/Partitioned Parallel Radix Sort 1{\_}Lee et al.pdf:pdf},
	Isbn = {9783540411284},
	Issn = {07437315},
	Journal = {Journal of Parallel and Distributed Computing},
	Number = {October 2000},
	Pages = {656--668},
	Title = {{Partitioned Parallel Radix Sort 1}},
	Volume = {668},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1006/jpdc.2001.1808}}

@article{Shen2015,
	Author = {Shen, Du and Luo, Qi and Poshyvanyk, Denys and Grechanik, Mark},
	Doi = {10.1145/2771783.2771816},
	File = {:Users/konstantinos/Google Drive/papers/Automating performance bottleneck detection using search-based application profiling{\_}Shen et al.pdf:pdf},
	Isbn = {9781450336208},
	Journal = {Proceedings of the 2015 International Symposium on Software Testing and Analysis - ISSTA 2015},
	Keywords = {all or part of,application profiling,or,or hard copies of,performance bottlenecks,permission to make digital,this work for personal},
	Pages = {270--281},
	Title = {{Automating performance bottleneck detection using search-based application profiling}},
	Url = {http://dl.acm.org/citation.cfm?doid=2771783.2771816},
	Year = {2015},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=2771783.2771816},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2771783.2771816}}

@article{Karras2012,
	Author = {Karras, Tero},
	Doi = {10.2312/EGGH/HPG12/033-037},
	File = {:Users/konstantinos/Google Drive/papers/Maximizing Parallelism in the Construction of BVHs , Octrees , and k-d Trees{\_}Karras.pdf:pdf},
	Isbn = {978-3-905674-41-5},
	Journal = {EGGH-HPG'12 Proceedings of the Fourth ACM SIGGRAPH / Eurographics conference on High-Performance Graphics},
	Pages = {33--37},
	Title = {{Maximizing Parallelism in the Construction of BVHs , Octrees , and k-d Trees}},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.2312/EGGH/HPG12/033-037}}

@article{Satish2009,
	Author = {Satish, Nadathur and Harris, Mark and Garland, Michael},
	File = {:Users/konstantinos/Google Drive/papers/Designing Efficient Sorting Algorithms for Manycore GPUs{\_}Satish, Harris, Garland.pdf:pdf},
	Journal = {Proceedings of 23rd IEEE International Parallel and Distributed Processing Symposium},
	Pages = {1--10},
	Title = {{Designing Efficient Sorting Algorithms for Manycore GPUs}},
	Year = {2009}}

@article{Gonnet2013,
	Author = {Gonnet, Pedro},
	File = {:Users/konstantinos/Google Drive/papers/QuickSched Task-based parallelism with dependencies and conflicts{\_}Gonnet.pdf:pdf},
	Keywords = {task-based parallelism},
	Pages = {1--25},
	Title = {{QuickSched: Task-based parallelism with dependencies and conflicts}},
	Year = {2013}}

